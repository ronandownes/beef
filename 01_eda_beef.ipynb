{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis Irish Beef\n",
    "## Research Question\n",
    "How has Ireland's beef sector performed compared to the EU 27 countries from 1961 to 2021, and can we forecast future prices using historical data? Additionally, what can we learn from sentiment analysis of the beef industry during this time period?\n",
    "## Libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Data Manipulation and Analysis\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fancyimpute\n",
    "import missingno as msno\n",
    "from functools import partial, reduce\n",
    "\n",
    "### Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "### Statistical Analysis\n",
    "from scipy.stats import ks_2samp, shapiro\n",
    "\n",
    "### Machine Learning\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet, Lasso, LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "### Text Processing\n",
    "import html\n",
    "import re\n",
    "\n",
    "### Country Information\n",
    "from countryinfo import CountryInfo\n",
    "import pycountry\n",
    "from countrygroups import EUROPEAN_UNION\n",
    "\n",
    "### File System and OS\n",
    "import glob\n",
    "import os\n",
    "\n",
    "### Date and Time\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "### Data Presentation\n",
    "from tabulate import tabulate\n",
    "from IPython.display import HTML, Image, display\n",
    "\n",
    "### Data Types\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ronan\\beef\n",
      "['.git', '.ipynb_checkpoints', '01_eda_beef.ipynb', '02_ml_beef.ipynb', '02_multivariate.ipynb', 'arch', 'beef-main.zip', 'beef.pdf', 'clean', 'css', 'data', 'ignore', 'images', 'rain', 'README.md', 'temperature', 'Untitled Folder', 'Untitled.ipynb']\n",
      "['alive.csv', 'stocks.csv', 'temperature.csv', 'temperature_change.csv', 'temperature_sd.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd()) # working directory.\n",
    "print(os.listdir('.')) #List current directory\n",
    "print(os.listdir('data')) # Our source files from FAOSTAT are in 'data' folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1708, 14)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/stocks.csv')# loads the cattle stock  CSV file to pandas DataFrame n df\n",
    "print(df.shape) # Inspect the dimensions of the dataset (number of rows and columns). (1708, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply data exploration functions to livestock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain Code</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Area Code (M49)</th>\n",
       "      <th>Area</th>\n",
       "      <th>Element Code</th>\n",
       "      <th>Element</th>\n",
       "      <th>Item Code (CPC)</th>\n",
       "      <th>Item</th>\n",
       "      <th>Year Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Value</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Flag Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QCL</td>\n",
       "      <td>Crops and livestock products</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>2111</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>Head</td>\n",
       "      <td>2386761.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QCL</td>\n",
       "      <td>Crops and livestock products</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>2111</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>1962</td>\n",
       "      <td>1962</td>\n",
       "      <td>Head</td>\n",
       "      <td>2456557.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QCL</td>\n",
       "      <td>Crops and livestock products</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>2111</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>1963</td>\n",
       "      <td>1963</td>\n",
       "      <td>Head</td>\n",
       "      <td>2437123.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QCL</td>\n",
       "      <td>Crops and livestock products</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>2111</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>1964</td>\n",
       "      <td>1964</td>\n",
       "      <td>Head</td>\n",
       "      <td>2310667.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QCL</td>\n",
       "      <td>Crops and livestock products</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>2111</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>Head</td>\n",
       "      <td>2350269.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Domain Code                        Domain  Area Code (M49)     Area  \\\n",
       "0         QCL  Crops and livestock products               40  Austria   \n",
       "1         QCL  Crops and livestock products               40  Austria   \n",
       "2         QCL  Crops and livestock products               40  Austria   \n",
       "3         QCL  Crops and livestock products               40  Austria   \n",
       "4         QCL  Crops and livestock products               40  Austria   \n",
       "\n",
       "   Element Code Element  Item Code (CPC)    Item  Year Code  Year  Unit  \\\n",
       "0          5111  Stocks             2111  Cattle       1961  1961  Head   \n",
       "1          5111  Stocks             2111  Cattle       1962  1962  Head   \n",
       "2          5111  Stocks             2111  Cattle       1963  1963  Head   \n",
       "3          5111  Stocks             2111  Cattle       1964  1964  Head   \n",
       "4          5111  Stocks             2111  Cattle       1965  1965  Head   \n",
       "\n",
       "       Value Flag Flag Description  \n",
       "0  2386761.0    A  Official figure  \n",
       "1  2456557.0    A  Official figure  \n",
       "2  2437123.0    A  Official figure  \n",
       "3  2310667.0    A  Official figure  \n",
       "4  2350269.0    A  Official figure  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head()#: returns the first few rows of the DataFrame indicating many fields may be invariant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Domain Code          object\n",
       "Domain               object\n",
       "Area Code (M49)       int64\n",
       "Area                 object\n",
       "Element Code          int64\n",
       "Element              object\n",
       "Item Code (CPC)       int64\n",
       "Item                 object\n",
       "Year Code             int64\n",
       "Year                  int64\n",
       "Unit                 object\n",
       "Value               float64\n",
       "Flag                 object\n",
       "Flag Description     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Domain Code            1\n",
       "Domain                 1\n",
       "Area Code (M49)       28\n",
       "Area                  28\n",
       "Element Code           1\n",
       "Element                1\n",
       "Item Code (CPC)        1\n",
       "Item                   1\n",
       "Year Code             61\n",
       "Year                  61\n",
       "Unit                   1\n",
       "Value               1365\n",
       "Flag                   3\n",
       "Flag Description       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values \n",
    "df.nunique() #  We have 28  country/ regions repoorting and 61 years of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The df.nunique() method reveals  2 issues in categorical data.\n",
    "\n",
    "1. Flag Description \n",
    "- We have 1160\t\tEstimated values\n",
    "- and 1182 \tUnofficial figure\n",
    "- In the context of this data analysis, these \"estimated value\" and \"unofficial figures\" might have  significant impact on the accuracy and reliability of our conclusion. \n",
    "2. The European Union (EU) is a political and economic union of 27 member states and yet we have 28  unique values of Area. This is more pressing than the flag describtiopns and is investigated first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flag</th>\n",
       "      <th>Flag Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>E</td>\n",
       "      <td>Estimated value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>T</td>\n",
       "      <td>Unofficial figure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Flag   Flag Description\n",
       "0       A    Official figure\n",
       "61    NaN                NaN\n",
       "1160    E    Estimated value\n",
       "1182    T  Unofficial figure"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_df = df[['Flag', 'Flag Description']].drop_duplicates()\n",
    "flag_df # There are a lot of estimated and missing categories of reporting- We will hold back on dealing with this for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain Code           0\n",
      "Domain                0\n",
      "Area Code (M49)       0\n",
      "Area                  0\n",
      "Element Code          0\n",
      "Element               0\n",
      "Item Code (CPC)       0\n",
      "Item                  0\n",
      "Year Code             0\n",
      "Year                  0\n",
      "Unit                319\n",
      "Value               319\n",
      "Flag                319\n",
      "Flag Description    319\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)#  Check for missing values shows 319 cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Belgium-Luxembourg started reporting beef stocks independently in 2000\n",
    "As part of the BLEU, Belgium and Luxembourg often reported their beef stock numbers as a single entity until 1999. After 1999, they started reporting independently.\n",
    "We zoom in on the df around 2000 and compare the three countries by plot with the Netherland s now acting as an exemplar of the rest of the coutries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Area\n",
      "0              Austria\n",
      "1              Belgium\n",
      "2   Belgium-Luxembourg\n",
      "3             Bulgaria\n",
      "4              Croatia\n",
      "5               Cyprus\n",
      "6              Czechia\n",
      "7              Denmark\n",
      "8              Estonia\n",
      "9              Finland\n",
      "10              France\n",
      "11             Germany\n",
      "12              Greece\n",
      "13             Hungary\n",
      "14             Ireland\n",
      "15               Italy\n",
      "16              Latvia\n",
      "17           Lithuania\n",
      "18          Luxembourg\n",
      "19               Malta\n",
      "20         Netherlands\n",
      "21              Poland\n",
      "22            Portugal\n",
      "23             Romania\n",
      "24            Slovakia\n",
      "25            Slovenia\n",
      "26               Spain\n",
      "27              Sweden\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming df is the DataFrame containing the 'Area' column\n",
    "unique_areas = df['Area'].unique()\n",
    "\n",
    "# Convert to a DataFrame and take a look to discover BELUX anomoly\n",
    "areasEU_df = pd.DataFrame({'Area': unique_areas})\n",
    "print(areasEU_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Belgium-Luxembourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bulgaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Croatia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Area\n",
       "0             Austria\n",
       "1             Belgium\n",
       "2  Belgium-Luxembourg\n",
       "3            Bulgaria\n",
       "4             Croatia"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write to CSV file\n",
    "areasEU_df.to_csv('clean/AreasEU.csv', index=False)\n",
    "areasEU_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Areas.csv', 'AreasEU.csv', 'benelux.csv', 'benelux_pivot.csv', 'cattle_stock.csv', 'country.csv', 'master_data.csv', 'stocks.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('clean')) # Not saying these are modelling ready but not source so into clean folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain Code</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Area Code (M49)</th>\n",
       "      <th>Area</th>\n",
       "      <th>Element Code</th>\n",
       "      <th>Element</th>\n",
       "      <th>Item Code (CPC)</th>\n",
       "      <th>Item</th>\n",
       "      <th>Year Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Value</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Flag Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>QCL</td>\n",
       "      <td>Crops and livestock products</td>\n",
       "      <td>58</td>\n",
       "      <td>Belgium-Luxembourg</td>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>2111</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>QCL</td>\n",
       "      <td>Crops and livestock products</td>\n",
       "      <td>528</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>2111</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>1979</td>\n",
       "      <td>1979</td>\n",
       "      <td>Head</td>\n",
       "      <td>4797000.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>QCL</td>\n",
       "      <td>Crops and livestock products</td>\n",
       "      <td>442</td>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>2111</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>1985</td>\n",
       "      <td>1985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>QCL</td>\n",
       "      <td>Crops and livestock products</td>\n",
       "      <td>442</td>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>2111</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>Head</td>\n",
       "      <td>201416.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>QCL</td>\n",
       "      <td>Crops and livestock products</td>\n",
       "      <td>56</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>2111</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>1991</td>\n",
       "      <td>1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Domain Code                        Domain  Area Code (M49)  \\\n",
       "178          QCL  Crops and livestock products               58   \n",
       "1238         QCL  Crops and livestock products              528   \n",
       "1122         QCL  Crops and livestock products              442   \n",
       "1153         QCL  Crops and livestock products              442   \n",
       "91           QCL  Crops and livestock products               56   \n",
       "\n",
       "                    Area  Element Code Element  Item Code (CPC)    Item  \\\n",
       "178   Belgium-Luxembourg          5111  Stocks             2111  Cattle   \n",
       "1238         Netherlands          5111  Stocks             2111  Cattle   \n",
       "1122          Luxembourg          5111  Stocks             2111  Cattle   \n",
       "1153          Luxembourg          5111  Stocks             2111  Cattle   \n",
       "91               Belgium          5111  Stocks             2111  Cattle   \n",
       "\n",
       "      Year Code  Year  Unit      Value Flag Flag Description  \n",
       "178        2017  2017   NaN        NaN  NaN              NaN  \n",
       "1238       1979  1979  Head  4797000.0    A  Official figure  \n",
       "1122       1985  1985   NaN        NaN  NaN              NaN  \n",
       "1153       2016  2016  Head   201416.0    A  Official figure  \n",
       "91         1991  1991   NaN        NaN  NaN              NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "benelux_df = df[df['Area'].isin(['Belgium-Luxembourg', 'Belgium', 'Luxembourg', 'Netherlands'])]\n",
    "benelux_df.sample(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the DataFrame with pivot()\n",
    "benelux_pivot_df = benelux_df.pivot(index='Year', columns='Area', values='Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns of the pivot table\n",
    "benelux_pivot_df.columns = ['{}_stock'.format(col.replace(' ', '_')) for col in benelux_pivot_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Belgium_stock</th>\n",
       "      <th>Belgium-Luxembourg_stock</th>\n",
       "      <th>Luxembourg_stock</th>\n",
       "      <th>Netherlands_stock</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2684120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3622588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2798130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3816942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2847478.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3695185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2641407.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3567379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2685510.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3750629.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>2385988.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202281.0</td>\n",
       "      <td>4030000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>2398090.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>194390.0</td>\n",
       "      <td>3690000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2373100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192100.0</td>\n",
       "      <td>3721000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>2335440.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190690.0</td>\n",
       "      <td>3691000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>2310440.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187200.0</td>\n",
       "      <td>3705000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Belgium_stock  Belgium-Luxembourg_stock  Luxembourg_stock  \\\n",
       "Year                                                              \n",
       "1961            NaN                 2684120.0               NaN   \n",
       "1962            NaN                 2798130.0               NaN   \n",
       "1963            NaN                 2847478.0               NaN   \n",
       "1964            NaN                 2641407.0               NaN   \n",
       "1965            NaN                 2685510.0               NaN   \n",
       "...             ...                       ...               ...   \n",
       "2017      2385988.0                       NaN          202281.0   \n",
       "2018      2398090.0                       NaN          194390.0   \n",
       "2019      2373100.0                       NaN          192100.0   \n",
       "2020      2335440.0                       NaN          190690.0   \n",
       "2021      2310440.0                       NaN          187200.0   \n",
       "\n",
       "      Netherlands_stock  \n",
       "Year                     \n",
       "1961          3622588.0  \n",
       "1962          3816942.0  \n",
       "1963          3695185.0  \n",
       "1964          3567379.0  \n",
       "1965          3750629.0  \n",
       "...                 ...  \n",
       "2017          4030000.0  \n",
       "2018          3690000.0  \n",
       "2019          3721000.0  \n",
       "2020          3691000.0  \n",
       "2021          3705000.0  \n",
       "\n",
       "[61 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the resulting pivot table\n",
    "benelux_pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Keep only the 'Area', 'Year'  and 'Value' columns\n",
    "# benelux = benelux[['Area','Year', 'Value']]\n",
    "\n",
    "\n",
    "# Write to CSV file\n",
    "benelux_pivot_df.to_csv('clean/benelux_pivot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Areas.csv', 'AreasEU.csv', 'benelux.csv', 'benelux_pivot.csv', 'cattle_stock.csv', 'country.csv', 'master_data.csv', 'stocks.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(os.listdir('clean'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Belgium_stock  Belgium-Luxembourg_stock  Luxembourg_stock  \\\n",
      "Year                                                              \n",
      "1997            NaN                 3280000.0               NaN   \n",
      "1998            NaN                 3184000.0               NaN   \n",
      "1999            NaN                 3395000.0               NaN   \n",
      "2000      3041560.0                       NaN          205072.0   \n",
      "2001      3037760.0                       NaN          205193.0   \n",
      "2002      2891260.0                       NaN          197257.0   \n",
      "\n",
      "      Netherlands_stock  \n",
      "Year                     \n",
      "1997          4411000.0  \n",
      "1998          4283000.0  \n",
      "1999          4206000.0  \n",
      "2000          4070000.0  \n",
      "2001          4047000.0  \n",
      "2002          3858000.0  \n"
     ]
    }
   ],
   "source": [
    "benelux_pivot = benelux_pivot_df.loc['1997':'2002']\n",
    "print(benelux_pivot.head(6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate historical  cattle stock reporting in the  BELUX union and Belgium  Luxembourg\n",
    "In Pandas, the unique() method was used above  used to return a unique array of values. We discovered that there were 28 unique entries for \"Area\" despite there being only 27 EU countries. Further investigation revealed that Belgium and Luxembourg reported economic data as one region, and the Netherlands also participated in the Benelux economic union with these two countries. To ensure a comprehensive investigation, we filtered the DataFrame to only include data from these three countries and The pivot() method in pandas was used to reshape the DataFrame and compare reporting and missing cattle stock reports.The  Netherlands reported cattle stock independently for all 61 years of our research interval, while Belgium \n",
    "and Luxembourg reported collectively as the Benelux region from 1961 to 1999 when they started reporting individually.\n",
    "## A revised research question\n",
    "How has Ireland's beef sector performed compared to the EU 27 countries since 2000, and can we forecast future prices using this historical data? Additionally, what can we learn from sentiment analysis of the beef industry during this time period? By focusing on data from 2000 onwards, we can better capture the current state of the beef industry and make more relevant predictions about future trends. At the end of 1999, the Benelux union ceased to report beef stock data as a single entity, as each member country began reporting its data individually. This change reflected the increasing economic development and growth of the individual countries within the union. This not only created the data reason for us to only researh the 21st era but it also provides a fiscal reason for the refining of the researh question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning to the master beef stock reporting file\n",
    "We load  the source  cattle stock CSV file to pandas again in case of interference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/stocks.csv')# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1708, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df=df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain Code           0\n",
      "Domain                0\n",
      "Area Code (M49)       0\n",
      "Area                  0\n",
      "Element Code          0\n",
      "Element               0\n",
      "Item Code (CPC)       0\n",
      "Item                  0\n",
      "Year Code             0\n",
      "Year                  0\n",
      "Unit                319\n",
      "Value               319\n",
      "Flag                319\n",
      "Flag Description    319\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of NaN values in each column\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter  strictly to  1999<year<2022\n",
    "Apart from solving the BELUX data cleaning problem recasting the research question to 2000-2021 acknowledges\n",
    " that \n",
    "farming in the 20th centuary was significantly different than from now so dropping this old data makes the data we keep more  relevant  for modelling current multivariate trends and predicting future trends along with suggested mittigations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creats a new DataFrame with Year>=2000 and keeps old  familiar name df\"\"\"\n",
    "df = df[df['Year'] >= 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['Area'] != 'Belgium-Luxembourg'] #Exclude 'Belgium-Luxembourg' from the 'Area' column in df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The df.nunique() method to identify invariant data\n",
    "The df.nunique() method returns the number of unique values in each column of our beef stocks data. This isuseful for identifying columns that have only one value like the **Domain** which is **Crops and livestock products**. All of this invariant data is redundant data that can be dropped to reduce the size of the DataFrame or improve the performance of data analyses. Note the Element header had **Stock** as every value and this was useful in that we used it to rename the Value field. It no longer of any use and gets the chop. selecting a subset of columns from a Pandas DataFrame. Selecting a  relatively small subset of columns is useful when you are keeping less than half of the fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Domain Code           1\n",
       "Domain                1\n",
       "Area Code (M49)      27\n",
       "Area                 27\n",
       "Element Code          1\n",
       "Element               1\n",
       "Item Code (CPC)       1\n",
       "Item                  1\n",
       "Year Code            22\n",
       "Year                 22\n",
       "Unit                  1\n",
       "Value               592\n",
       "Flag                  1\n",
       "Flag Description      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values \n",
    "df.nunique() #  We have 28  country/ regions repoorting and 61 years of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate the Belgium-Luxembourg\n",
    "\n",
    "By fixing our **BELUX** problem the estimation and unoffial stock reportig flags hae also dissapeared and we have killed two birds with the one stone so to speak! We will also do some relabelling and reduce dimesionality based on nvariant data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Value': 'Stocks', 'Area': 'Country'}) #Renamed 'Value' column to 'Stocks' and Area column to Country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain Code</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Area Code (M49)</th>\n",
       "      <th>Country</th>\n",
       "      <th>Element Code</th>\n",
       "      <th>Element</th>\n",
       "      <th>Item Code (CPC)</th>\n",
       "      <th>Item</th>\n",
       "      <th>Year Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Stocks</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Flag Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>QCL</td>\n",
       "      <td>Crops and livestock products</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>2111</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Head</td>\n",
       "      <td>2152811.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>QCL</td>\n",
       "      <td>Crops and livestock products</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>2111</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2001</td>\n",
       "      <td>2001</td>\n",
       "      <td>Head</td>\n",
       "      <td>2155447.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>QCL</td>\n",
       "      <td>Crops and livestock products</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>2111</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>Head</td>\n",
       "      <td>2118454.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>QCL</td>\n",
       "      <td>Crops and livestock products</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>2111</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Head</td>\n",
       "      <td>2066942.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>QCL</td>\n",
       "      <td>Crops and livestock products</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5111</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>2111</td>\n",
       "      <td>Cattle</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004</td>\n",
       "      <td>Head</td>\n",
       "      <td>2052033.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Domain Code                        Domain  Area Code (M49)  Country  \\\n",
       "39         QCL  Crops and livestock products               40  Austria   \n",
       "40         QCL  Crops and livestock products               40  Austria   \n",
       "41         QCL  Crops and livestock products               40  Austria   \n",
       "42         QCL  Crops and livestock products               40  Austria   \n",
       "43         QCL  Crops and livestock products               40  Austria   \n",
       "\n",
       "    Element Code Element  Item Code (CPC)    Item  Year Code  Year  Unit  \\\n",
       "39          5111  Stocks             2111  Cattle       2000  2000  Head   \n",
       "40          5111  Stocks             2111  Cattle       2001  2001  Head   \n",
       "41          5111  Stocks             2111  Cattle       2002  2002  Head   \n",
       "42          5111  Stocks             2111  Cattle       2003  2003  Head   \n",
       "43          5111  Stocks             2111  Cattle       2004  2004  Head   \n",
       "\n",
       "       Stocks Flag Flag Description  \n",
       "39  2152811.0    A  Official figure  \n",
       "40  2155447.0    A  Official figure  \n",
       "41  2118454.0    A  Official figure  \n",
       "42  2066942.0    A  Official figure  \n",
       "43  2052033.0    A  Official figure  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # Check that  filtering and renaming worked correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Country\", \"Year\", \"Stocks\", \"Flag\", \"Flag Description\"]] # Easier to stipulate what we keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Stocks</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Flag Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2017</td>\n",
       "      <td>1448590.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2018</td>\n",
       "      <td>1435450.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2019</td>\n",
       "      <td>1404670.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2020</td>\n",
       "      <td>1390960.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2021</td>\n",
       "      <td>1389890.0</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Year     Stocks Flag Flag Description\n",
       "1703  Sweden  2017  1448590.0    A  Official figure\n",
       "1704  Sweden  2018  1435450.0    A  Official figure\n",
       "1705  Sweden  2019  1404670.0    A  Official figure\n",
       "1706  Sweden  2020  1390960.0    A  Official figure\n",
       "1707  Sweden  2021  1389890.0    A  Official figure"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape# returns the dimensions of the DataFrame as (1708, 14)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country              object\n",
      "Year                  int64\n",
      "Stocks              float64\n",
      "Flag                 object\n",
      "Flag Description     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country             0\n",
       "Year                0\n",
       "Stocks              0\n",
       "Flag                0\n",
       "Flag Description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()# returns the number of missing values in each column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lack of estimated and unofficial reporting\n",
    "Lack of estimated and unofficial reporting makes the Flag and  Flag Description field reduntant so we drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flag</th>\n",
       "      <th>Flag Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Flag Flag Description\n",
       "39    A  Official figure"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_df = df[['Flag', 'Flag Description']].drop_duplicates()\n",
    "flag_df # Unofficial and estimated reports were illiminated with other interventions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country              object\n",
       "Year                  int64\n",
       "Stocks              float64\n",
       "Flag                 object\n",
       "Flag Description     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The devil is in the dtypes!\n",
    "\n",
    "While there is a somewhat academic exposition into the importance of approriate use of the Int type for discreet values $\\mathbb{Z} $  and the floating type to represent real numbers  $\\mathbb{R}$ suffice to say here that integers are for counting and as well as counting sheep we count cattle and that is the end of it. Bad things can  happen when floating points are used for discreet values and even if they don't we slow down our modelling.\n",
    "\n",
    "Also int64 can represent a much larger range of values than int32, but it also requires more memory so we will recast the Year type from INT64 to INT32.  If we are still farning in two billion years in the year  2,147,483,647  someone or some bovine  can cast it back up to INT64 depending on evolution and who is in charge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The absence of missing Stock values enables us to only now cast them as 32-bit integers\n",
    "Now that there are no missing values in the 'Stock' column of our  Pandas DataFrame, df,  you can cast the  'Stock' column to a 32-bit integer data type using the astype() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2147483647\n"
     ]
    }
   ],
   "source": [
    "max_int32 = int(2**32/2-1)\n",
    "print(max_int32)  # the /2 is because integers are directed numbers and the -1 accounts for 0!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country             object\n",
       "Year                 int32\n",
       "Stocks               int32\n",
       "Flag                object\n",
       "Flag Description    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The absence of mising values frees us up to cast values to integers. We can't have live bovine parts!\n",
    "df['Stocks'] = df['Stocks'].astype(int)\n",
    "# Cast the 'Year' column from int64 to int32\n",
    "df['Year'] = df['Year'].astype('int32')\n",
    "df.dtypes # Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 594 entries, 39 to 1707\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Country           594 non-null    object\n",
      " 1   Year              594 non-null    int32 \n",
      " 2   Stocks            594 non-null    int32 \n",
      " 3   Flag              594 non-null    object\n",
      " 4   Flag Description  594 non-null    object\n",
      "dtypes: int32(2), object(3)\n",
      "memory usage: 23.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()# provides a concise summary of the DataFrame, including column data types, non-null values, and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Stocks</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Flag Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2000</td>\n",
       "      <td>2152811</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2001</td>\n",
       "      <td>2155447</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2002</td>\n",
       "      <td>2118454</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2003</td>\n",
       "      <td>2066942</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2004</td>\n",
       "      <td>2052033</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country  Year   Stocks Flag Flag Description\n",
       "39  Austria  2000  2152811    A  Official figure\n",
       "40  Austria  2001  2155447    A  Official figure\n",
       "41  Austria  2002  2118454    A  Official figure\n",
       "42  Austria  2003  2066942    A  Official figure\n",
       "43  Austria  2004  2052033    A  Official figure"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Flag', 'Flag Description'], axis=1) # Removed two columns from the DataFrame as all reporting is official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Stocks'] = df['Stocks'].astype(int) # Naive reason: Integers are for counting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Jupyter Notebook has focussed on cleaning our target variable \n",
    "- Lets punctuate the workflow by  continue with quality checking, visualisation, and merging data in the next Notebook.\n",
    "- We will need to do some rigorous testing and visualisaton on it as well as merging it with expected predictor variables before any modelling and machine learning but progress has been made along with piles of enjoyable learning on the authors part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Stocks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2000</td>\n",
       "      <td>2152811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2001</td>\n",
       "      <td>2155447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2002</td>\n",
       "      <td>2118454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2003</td>\n",
       "      <td>2066942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2004</td>\n",
       "      <td>2052033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2017</td>\n",
       "      <td>1448590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2018</td>\n",
       "      <td>1435450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2019</td>\n",
       "      <td>1404670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2020</td>\n",
       "      <td>1390960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2021</td>\n",
       "      <td>1389890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Country  Year   Stocks\n",
       "39    Austria  2000  2152811\n",
       "40    Austria  2001  2155447\n",
       "41    Austria  2002  2118454\n",
       "42    Austria  2003  2066942\n",
       "43    Austria  2004  2052033\n",
       "...       ...   ...      ...\n",
       "1703   Sweden  2017  1448590\n",
       "1704   Sweden  2018  1435450\n",
       "1705   Sweden  2019  1404670\n",
       "1706   Sweden  2020  1390960\n",
       "1707   Sweden  2021  1389890\n",
       "\n",
       "[594 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'clean/master_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5660\\3986647547.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'clean/master_data.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Stash it away\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3549\u001b[0m         )\n\u001b[0;32m   3550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3551\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3552\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3553\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1178\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         )\n\u001b[1;32m-> 1180\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \"\"\"\n\u001b[0;32m    240\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'clean/master_data.csv'"
     ]
    }
   ],
   "source": [
    "df.to_csv('clean/master_data.csv', index=False) # Stash it away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Areas.csv', 'AreasEU.csv', 'benelux.csv', 'benelux_pivot.csv', 'cattle_stock.csv', 'country.csv', 'master_data.csv', 'stocks.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('clean')) # make sure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn of the lights and save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by country and select the column of interest\n",
    "grouped = df.groupby('Country')['column_name']\n",
    "\n",
    "# Create a box plot for the grouped data\n",
    "plt.boxplot(grouped)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_producers = df.groupby('Country')['Stocks'].sum().sort_values(ascending=False).head(5)\n",
    "print(top_producers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_grouped = df.groupby('Country')['Stocks'].sum().reset_index()\n",
    "df_grouped = df_grouped.sort_values(by='Stocks', ascending=False).reset_index(drop=True)\n",
    "\n",
    "plt.bar(df_grouped['Country'][:10], df_grouped['Stocks'][:10])\n",
    "plt.title('Top 10 Beef Producing Countries in European Union (EU) ' )\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Total Stocks')\n",
    "\n",
    "plt.xticks(rotation=90)  # rotate the x-axis labels by 90 degrees\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_grouped = df.groupby('Country')['Stocks'].sum().reset_index()\n",
    "df_grouped = df_grouped.sort_values(by='Stocks', ascending=False).reset_index(drop=True)\n",
    "\n",
    "plt.bar(df_grouped['Country'][:10], df_grouped['Stocks'][:10])\n",
    "plt.title('Top 10 Beef Producing Countries in European Union (EU) ')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Total Stocks')\n",
    "\n",
    "plt.xticks(rotation=90)  # rotate the x-axis labels by 90 degrees\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_grouped = df.groupby('Country')['Stocks'].sum().reset_index()\n",
    "df_grouped = df_grouped.sort_values(by='Stocks', ascending=False).reset_index(drop=True)\n",
    "\n",
    "plt.bar(df_grouped['Country'][:len(df_grouped)], df_grouped['Stocks'][:len(df_grouped)])\n",
    "\n",
    "plt.title('Distribution of Beef  Stocks  in European Union (EU) ')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Total Stocks')\n",
    "\n",
    "plt.xticks(rotation=90)  # rotate the x-axis labels by 90 degrees\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_heatmap = df.pivot_table(index='Country', columns='Year', values='Stocks')\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df_heatmap, cmap='YlOrRd', annot=True, fmt='g')\n",
    "plt.title('Distribution of Beef Stocks Production by Country and Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Country')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Beef Stocks Production by Country and Year\n",
    "\n",
    "Code uses a pivot table with the country names as the index, year as the columns, and beef stocks as the values. Then, it uses seaborn to create a heatmap with annotations that display the beef stocks production by country and year. The cmap parameter sets the color palette, and fmt='g' sets the format for the annotations to be in plain numbers. The plt.title(), plt.xlabel(), and plt.ylabel() functions are used to label the heatmap.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Filter the original dataset to keep only data for Ireland, France, and Germany from 2000 onwards\n",
    "beef_df = df.loc[df['Country'].isin(['Ireland', 'France', 'Germany']) & (df['Year'] >= 2000)]\n",
    "\n",
    "# 2. Group the filtered dataset by year and country and calculate the total beef production for each group\n",
    "beef_production = beef_df.groupby(['Year', 'Country'])['Stocks'].sum().reset_index()\n",
    "\n",
    "# 3. Create separate line charts for each country\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('dark')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(data=beef_production, x='Year', y='Stocks', hue='Country', ax=ax)\n",
    "\n",
    "# 4. Compare the trends in beef production over time for each country\n",
    "plt.title('Beef Production in Ireland, France, and Germany since 2000')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Beef Production (in 1000 metric tons)')\n",
    "plt.legend(title='Country')\n",
    "\n",
    "# 5. Summarize your findings and draw conclusions about the similarities and differences in beef production among the three countries since 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Country')# groups the DataFrame by one or more columns and applies a function to each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert dataframe to list of lists\n",
    "table = ds.values.tolist()\n",
    "\n",
    "\n",
    "\n",
    "# use tabulate to create a table\n",
    "print(tabulate(table, headers, tablefmt='latex_booktabs'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Pandas DataFrame,'df' in latex table out\n",
    "table = tabulate(df.sample(40), headers='keys', tablefmt='latex', floatfmt=\".2f\")\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_rotated_table(df: pd.DataFrame, caption: str, label: str) -> str:\n",
    "    # Start the LaTeX tabular environment\n",
    "    latex = \"\\\\begin{table}[h]\\n\"\n",
    "    latex += \"\\\\centering\\n\"\n",
    "    latex += \"\\\\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}\\n\"\n",
    "    latex += \"\\\\hline\\n\"\n",
    "    \n",
    "    # Add the table headers\n",
    "    headers = list(df.columns)\n",
    "    for header in headers:\n",
    "        latex += \"\\\\rotatebox{90}{\" + header + \"} & \"\n",
    "    latex = latex[:-2] + \"\\\\\\\\\\n\"\n",
    "    latex += \"\\\\hline\\n\"\n",
    "    \n",
    "    # Add the table rows\n",
    "    for row in df.iterrows():\n",
    "        latex += \" & \".join([str(item) for item in row[1]]) + \" \\\\\\\\\\n\"\n",
    "    \n",
    "    # End the LaTeX tabular environment and add the caption and label\n",
    "    latex += \"\\\\hline\\n\"\n",
    "    latex += \"\\\\end{tabular}\\n\"\n",
    "    latex += \"\\\\caption{\" + caption + \"}\\n\"\n",
    "    latex += \"\\\\label{\" + label + \"}\\n\"\n",
    "    latex += \"\\\\end{table}\"\n",
    "    \n",
    "    return latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume your data is in a pandas DataFrame called 'df'\n",
    "table = tabulate(livestock, headers='keys', tablefmt='latex', floatfmt=\".2f\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_rotated_table(df.sample(40),'Sample of Livestock data before EDA','tab:livestock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert df to a LaTeX table\n",
    "table = tabulate(df, headers='keys', tablefmt='latex')\n",
    "# Print the LaTeX table\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop Belgium-Luxembourg\n",
    "# Drop \"Production\" column\n",
    "df = df.drop(df[df['Area'] == 'Belgium-Luxembourg'].index)\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of the DataFrame\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of unique countries from the \"Area\" column\n",
    "countries = df['Area'].unique()\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# count the number of missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# print the result\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of areas with missing values\n",
    "num_missing_areas = df['Area'][df.isna().any(axis=1)].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(\"The number of areas with missing values is:\", num_missing_areas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "31900/1708 # 20% data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snake('Distribution of Missing Values by Area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snake('msno.matrix(df)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a bar chart of the missing value counts by year\n",
    "plt.figure(figsize=(20,8))  # increase the figure size for better readability\n",
    "ax = year_counts.plot(kind='bar')\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Number of Missing Values', fontsize=14)\n",
    "plt.title('Distribution of Missing Values by Year', fontsize=18)\n",
    "plt.xticks(rotation=0, fontsize=12)  # rotate x-axis labels to 0 degrees\n",
    "ax.tick_params(axis='y', labelsize=12)  # adjust y-axis label size\n",
    "ax.tick_params(axis='x', pad=10)  # adjust x-axis tick padding\n",
    "\n",
    "# add value labels to the bars\n",
    "for i, v in enumerate(year_counts):\n",
    "    ax.text(i, v, str(v), ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "\n",
    "# set year labels vertically\n",
    "ax.set_xticklabels(year_counts.index, rotation=90)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "A new dataframe with counts of missing values \n",
    "for each country was sorted in descending order\n",
    "revealing  the top 10 countries\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# create a new dataframe to hold the counts of missing values by country\n",
    "country_counts = df.isnull().sum(axis=1).groupby(df.Area).sum().sort_values(ascending=False)\n",
    "\n",
    "# get the top 10 countries with the most missing values\n",
    "top_10_countries = country_counts.head(10)\n",
    "\n",
    "# print the list of top 10 countries\n",
    "print(top_10_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe to hold the counts of missing values by country\n",
    "country_counts = df.isnull().sum(axis=1).groupby(df.Area).sum().sort_values(ascending=True)\n",
    "\n",
    "# get the list of countries with any missing values\n",
    "missing_countries = country_counts[country_counts > 0].index\n",
    "\n",
    "# print the list of countries with missing values\n",
    "print(\"Countries with missing values:\\n\", missing_countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe to hold the counts of missing values by country\n",
    "country_counts = df.isnull().sum(axis=1).groupby(df.Area).sum().sort_values(ascending=True)\n",
    "\n",
    "# get the list of countries with any missing values\n",
    "missing_countries = country_counts[country_counts > 0].index\n",
    "\n",
    "# print the list of countries with missing values\n",
    "print(\"Countries with missing values:\\n\", missing_countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe to hold the counts of missing values by country\n",
    "country_counts = df.isnull().sum(axis=1).groupby(df.Area).sum().sort_values(ascending=True)\n",
    "\n",
    "# get the list of countries with any missing values\n",
    "missing_countries = country_counts[country_counts > 0]\n",
    "\n",
    "# create a new dataframe with the missing value counts and the total number of observations for each country\n",
    "mv_counts = pd.concat([missing_countries, df.groupby('Area').size()], axis=1)\n",
    "mv_counts.columns = ['Missing Values', 'Total Observations']\n",
    "\n",
    "# calculate the proportion of missing values for each country\n",
    "mv_counts['% Missing'] = mv_counts['Missing Values'] / mv_counts['Total Observations'] * 100\n",
    "\n",
    "# sort the dataframe by the proportion of missing values in descending order\n",
    "mv_counts = mv_counts.sort_values('% Missing', ascending=False)\n",
    "\n",
    "# display the table\n",
    "print(mv_counts.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# group the data by Area and compute the total count of missing values for each group\n",
    "area_counts = df.isnull().sum(axis=1).groupby(df.Area).sum()\n",
    "\n",
    "# create a bar chart of the missing value counts by Area\n",
    "plt.figure(figsize=(10,5))\n",
    "ax = area_counts.plot(kind='bar')\n",
    "plt.xlabel('Area')\n",
    "plt.ylabel('Number of Missing Values')\n",
    "plt.title('Distribution of Missing Values by Area')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# add value labels to the bars\n",
    "for i, v in enumerate(area_counts):\n",
    "    ax.text(i, v, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_describtions = df['Flag Description'].unique()\n",
    "print(unique_describtions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[df['Year'] > 1999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents (Clickable in sidebar)<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Research-Question\" data-toc-modified-id=\"Research-Question-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Research Question</a></span></li><li><span><a href=\"#Libraries-and-modules\" data-toc-modified-id=\"Libraries-and-modules-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Libraries and modules</a></span></li><li><span><a href=\"#Housekeeping\" data-toc-modified-id=\"Housekeeping-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Housekeeping</a></span></li><li><span><a href=\"#Apply-data-exploration-functions-to-livestock-data\" data-toc-modified-id=\"Apply-data-exploration-functions-to-livestock-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Apply data exploration functions to livestock data</a></span></li><li><span><a href=\"#The-df.nunique()-method-reveals--2-issues-in-categorical-data.\" data-toc-modified-id=\"The-df.nunique()-method-reveals--2-issues-in-categorical-data.-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>The df.nunique() method reveals  2 issues in categorical data.</a></span></li><li><span><a href=\"#Belgium-Luxembourg-started-reporting-beef-stocks-independently-in-2000\" data-toc-modified-id=\"Belgium-Luxembourg-started-reporting-beef-stocks-independently-in-2000-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Belgium-Luxembourg started reporting beef stocks independently in 2000</a></span></li><li><span><a href=\"#Investigate-historical--cattle-stock-reporting-in-the--BELUX-union-and-Belgium--Luxembourg\" data-toc-modified-id=\"Investigate-historical--cattle-stock-reporting-in-the--BELUX-union-and-Belgium--Luxembourg-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Investigate historical  cattle stock reporting in the  BELUX union and Belgium  Luxembourg</a></span></li><li><span><a href=\"#A-revised-research-question\" data-toc-modified-id=\"A-revised-research-question-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>A revised research question</a></span></li><li><span><a href=\"#Returning-to-the-master-beef-stock-reporting-file\" data-toc-modified-id=\"Returning-to-the-master-beef-stock-reporting-file-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Returning to the master beef stock reporting file</a></span></li><li><span><a href=\"#Filter--strictly-to--1999<year<2022\" data-toc-modified-id=\"Filter--strictly-to--1999<year<2022-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Filter  strictly to  1999&lt;year&lt;2022</a></span></li><li><span><a href=\"#The-df.nunique()-method-to-identify-invariant-data\" data-toc-modified-id=\"The-df.nunique()-method-to-identify-invariant-data-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>The df.nunique() method to identify invariant data</a></span></li><li><span><a href=\"#Eliminate-the-Belgium-Luxembourg\" data-toc-modified-id=\"Eliminate-the-Belgium-Luxembourg-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Eliminate the Belgium-Luxembourg</a></span></li><li><span><a href=\"#Lack-of-estimated-and-unofficial-reporting\" data-toc-modified-id=\"Lack-of-estimated-and-unofficial-reporting-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Lack of estimated and unofficial reporting</a></span></li><li><span><a href=\"#The-devil-is-in-the-dtypes!\" data-toc-modified-id=\"The-devil-is-in-the-dtypes!-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>The devil is in the dtypes!</a></span></li><li><span><a href=\"#The-absence-of-missing-Stock-values-enables-us-to-only-now-cast-them-as-32-bit-integers\" data-toc-modified-id=\"The-absence-of-missing-Stock-values-enables-us-to-only-now-cast-them-as-32-bit-integers-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>The absence of missing Stock values enables us to only now cast them as 32-bit integers</a></span></li><li><span><a href=\"#This-Jupyter-Notebook-has-focussed-on-cleaning-our-target-variable\" data-toc-modified-id=\"This-Jupyter-Notebook-has-focussed-on-cleaning-our-target-variable-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>This Jupyter Notebook has focussed on cleaning our target variable</a></span></li><li><span><a href=\"#Turn-of-the-lights-and-save-memory\" data-toc-modified-id=\"Turn-of-the-lights-and-save-memory-17\"><span class=\"toc-item-num\">17&nbsp;&nbsp;</span>Turn of the lights and save memory</a></span></li><li><span><a href=\"#Visualisation\" data-toc-modified-id=\"Visualisation-18\"><span class=\"toc-item-num\">18&nbsp;&nbsp;</span>Visualisation</a></span></li><li><span><a href=\"#Distribution-of-Beef-Stocks-Production-by-Country-and-Year\" data-toc-modified-id=\"Distribution-of-Beef-Stocks-Production-by-Country-and-Year-19\"><span class=\"toc-item-num\">19&nbsp;&nbsp;</span>Distribution of Beef Stocks Production by Country and Year</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-20\"><span class=\"toc-item-num\">20&nbsp;&nbsp;</span>Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Input/Output:\" data-toc-modified-id=\"Data-Input/Output:-20.1\"><span class=\"toc-item-num\">20.1&nbsp;&nbsp;</span>Data Input/Output:</a></span></li><li><span><a href=\"#Data-Cleaning:\" data-toc-modified-id=\"Data-Cleaning:-20.2\"><span class=\"toc-item-num\">20.2&nbsp;&nbsp;</span>Data Cleaning:</a></span></li><li><span><a href=\"#Data-Exploration:\" data-toc-modified-id=\"Data-Exploration:-20.3\"><span class=\"toc-item-num\">20.3&nbsp;&nbsp;</span>Data Exploration:</a></span></li><li><span><a href=\"#Data-Transformation\" data-toc-modified-id=\"Data-Transformation-20.4\"><span class=\"toc-item-num\">20.4&nbsp;&nbsp;</span>Data Transformation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Split\" data-toc-modified-id=\"Split-20.4.1\"><span class=\"toc-item-num\">20.4.1&nbsp;&nbsp;</span>Split</a></span></li></ul></li><li><span><a href=\"#Data-Combination:\" data-toc-modified-id=\"Data-Combination:-20.5\"><span class=\"toc-item-num\">20.5&nbsp;&nbsp;</span>Data Combination:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pascal\" data-toc-modified-id=\"Pascal-20.5.1\"><span class=\"toc-item-num\">20.5.1&nbsp;&nbsp;</span>Pascal</a></span></li><li><span><a href=\"#Total-Character\" data-toc-modified-id=\"Total-Character-20.5.2\"><span class=\"toc-item-num\">20.5.2&nbsp;&nbsp;</span>Total Character</a></span></li></ul></li><li><span><a href=\"#Scanners,--Readers-and-Writers\" data-toc-modified-id=\"Scanners,--Readers-and-Writers-20.6\"><span class=\"toc-item-num\">20.6&nbsp;&nbsp;</span>Scanners,  Readers and Writers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scanners\" data-toc-modified-id=\"Scanners-20.6.1\"><span class=\"toc-item-num\">20.6.1&nbsp;&nbsp;</span>Scanners</a></span></li><li><span><a href=\"#Readers\" data-toc-modified-id=\"Readers-20.6.2\"><span class=\"toc-item-num\">20.6.2&nbsp;&nbsp;</span>Readers</a></span></li><li><span><a href=\"#Splitters\" data-toc-modified-id=\"Splitters-20.6.3\"><span class=\"toc-item-num\">20.6.3&nbsp;&nbsp;</span>Splitters</a></span></li><li><span><a href=\"#Delete\" data-toc-modified-id=\"Delete-20.6.4\"><span class=\"toc-item-num\">20.6.4&nbsp;&nbsp;</span>Delete</a></span></li><li><span><a href=\"#Rename\" data-toc-modified-id=\"Rename-20.6.5\"><span class=\"toc-item-num\">20.6.5&nbsp;&nbsp;</span>Rename</a></span></li><li><span><a href=\"#Replace\" data-toc-modified-id=\"Replace-20.6.6\"><span class=\"toc-item-num\">20.6.6&nbsp;&nbsp;</span>Replace</a></span></li></ul></li><li><span><a href=\"#Data-Processing\" data-toc-modified-id=\"Data-Processing-20.7\"><span class=\"toc-item-num\">20.7&nbsp;&nbsp;</span>Data Processing</a></span></li><li><span><a href=\"#String-Manipulation\" data-toc-modified-id=\"String-Manipulation-20.8\"><span class=\"toc-item-num\">20.8&nbsp;&nbsp;</span>String Manipulation</a></span></li><li><span><a href=\"#File-System-Operations\" data-toc-modified-id=\"File-System-Operations-20.9\"><span class=\"toc-item-num\">20.9&nbsp;&nbsp;</span>File System Operations</a></span></li></ul></li><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-21\"><span class=\"toc-item-num\">21&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Modules-Functions-Libraries-and-How-to-Use\" data-toc-modified-id=\"Modules-Functions-Libraries-and-How-to-Use-22\"><span class=\"toc-item-num\">22&nbsp;&nbsp;</span>Modules Functions Libraries and How to Use</a></span></li><li><span><a href=\"#Appendices\" data-toc-modified-id=\"Appendices-23\"><span class=\"toc-item-num\">23&nbsp;&nbsp;</span>Appendices</a></span><ul class=\"toc-item\"><li><span><a href=\"#FAOSTAT-Data-Domains\" data-toc-modified-id=\"FAOSTAT-Data-Domains-23.1\"><span class=\"toc-item-num\">23.1&nbsp;&nbsp;</span>FAOSTAT Data Domains</a></span></li></ul></li><li><span><a href=\"#Climate--Data-Preparation\" data-toc-modified-id=\"Climate--Data-Preparation-24\"><span class=\"toc-item-num\">24&nbsp;&nbsp;</span>Climate  Data Preparation</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#About-FAOSTAT\" data-toc-modified-id=\"About-FAOSTAT-24.0.1\"><span class=\"toc-item-num\">24.0.1&nbsp;&nbsp;</span>About FAOSTAT</a></span></li><li><span><a href=\"#Licencing\" data-toc-modified-id=\"Licencing-24.0.2\"><span class=\"toc-item-num\">24.0.2&nbsp;&nbsp;</span>Licencing</a></span></li><li><span><a href=\"#CCKP-Data--and-an-initial-bit-of-EDA\" data-toc-modified-id=\"CCKP-Data--and-an-initial-bit-of-EDA-24.0.3\"><span class=\"toc-item-num\">24.0.3&nbsp;&nbsp;</span>CCKP Data  and an initial bit of EDA</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Key'] = df['Area'] + '_' + df['Year'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_values = df['Flag Description'].unique()\n",
    "print(flag_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Domain Code', 'Domain', 'Area Code (M49)', 'Element Code', 'Element', 'Item Code (CPC)', 'Year Code', 'Year', 'Unit', 'Flag Description'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# count the frequency of NaN and 'Official figure' values in the 'Flag Description' column\n",
    "flag_counts = df['Flag Description'].value_counts(dropna=False)\n",
    "\n",
    "# plot a pie chart of the flag counts\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(flag_counts, labels=flag_counts.index, autopct='%1.1f%%')\n",
    "plt.title('Flag Description Frequencies')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_countries = df[df.isna().any(axis=1)]['Area'].unique()\n",
    "\n",
    "print(nan_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_areas = df['Area'].unique()\n",
    "print(unique_areas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_data = df[df['Area'] == 'Belgium-Luxembourg']\n",
    "bl_data.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luxembourg_data = df[df[\"Area\"] == \"Luxembourg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Area\"] == \"Luxembourg\"].head(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Area'] == 'Belgium'].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_areas = df['Area'].nunique()\n",
    "print('Number of unique areas:', num_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows for Belgium-Luxembourg\n",
    "df = df.drop(index=df[df[\"Area\"] == \"Belgium-Luxembourg\"].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "removeing extraneous columns\n",
    "\"\"\"\n",
    "\n",
    "df = df.drop(['flag','Domain Code', 'Domain', 'Area Code (M49)', 'Element Code', 'Element', 'Item Code (CPC)', 'Year Code', 'Year', 'Unit', 'Flag Description'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"  \n",
    "####  Transform \n",
    "\n",
    "The transform function reads in a CSV file, renames a column, \n",
    "and filters the resulting dataframe to only include the 'key' \n",
    "and specified column. It returns the resulting dataframe after\n",
    "renaming the specified column and filtering.\n",
    "\"\"\"\n",
    "\n",
    "def transform(path: str, filename: str, col_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Reads in a CSV file from the given directory, renames a column to the given column name, and\n",
    "    filters the resulting dataframe to only include the 'key' and specified column.\n",
    "    \n",
    "    Args:\n",
    "        path (str): The relative path of the directory containing the data.\n",
    "        filename (str): The name of the CSV file to read in.\n",
    "        col_name (str): The name to assign to the specified column in the resulting dataframe.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: The resulting dataframe after renaming the specified column and filtering\n",
    "        to only include the 'key' and specified column.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = os.path.join(path, filename)\n",
    "        df = pd.read_csv(file_path, on_bad_lines='skip', skiprows=1)\n",
    "        df.rename(columns={'Unnamed: 0': 'Year'}, inplace=True)\n",
    "        df['key'] = df.columns[1] + df['Year'].astype(str)\n",
    "        df.rename(columns={df.columns[1]: col_name}, inplace=True)\n",
    "        df = df.filter(['key', col_name])\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading in CSV file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "####  Combine Files\n",
    "\n",
    "The combine function is designed to read in all  the **precicipitation**\n",
    "or **mean-temperature** CSV files  from either the 'pr' or 'ts' folders,\n",
    "apply the transform function to each file to rename a column with the country \n",
    "the data relates to and filter at the superregional level. It then combines    \n",
    "all the the resulting dataframes together into a single dataframe for all the 27 EU counties.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def combine(path: str, subfolder: str, col_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Reads in all CSV files in the given subfolder of the directory, applies the 'transform' function to each file, and\n",
    "    combines the resulting dataframes together into a single dataframe.\n",
    "    \n",
    "    Args:\n",
    "        path (str): The relative path of the directory containing the data.\n",
    "        subfolder (str): The name of the subfolder within the directory to read the CSV files from.\n",
    "        col_name (str): The name to assign to the specified column in the resulting dataframe.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: The resulting dataframe after combining data from all CSV files in the\n",
    "        specified subfolder.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        folder_path = os.path.join(path, subfolder)\n",
    "        csv_filenames = glob.glob(folder_path + \"/*.csv\")\n",
    "        processed_dfs = (transform(path, os.path.join(subfolder, os.path.basename(FileName)), col_name) for FileName in csv_filenames)\n",
    "        df = pd.concat(processed_dfs, ignore_index=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error combining CSV files in folder {folder_path}: {e}\")\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#### Temp Â°C  Preparation\n",
    "\n",
    "All 27 'pr_timeseries_annual_cru' and 27 'tas_timeseries_annual_cru' \n",
    "files will be processed into 'rain.df' &'rain.csv' and 'temp.df' & 'temp.csv' accordingly.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Load the 'tas' data from the '../data' directory and create a dataframe 'temp_df'\n",
    "# with the 'Temp Â°C' data. \n",
    "temp_df = combine('../data', 'tas', 'Temp \\u00B0C')\n",
    "\n",
    "# Display the first few rows of the 'temp_df' dataframe.\n",
    "temp_df.head()\n",
    "\n",
    "# Save the 'temp_df' dataframe to a CSV file in the '../data/processed' directory, \n",
    "# with the filename 'temp.csv', and exclude the index column from the output.\n",
    "temp_df.to_csv('../data/processed/temp.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the 'temp_df' dataframe again.\n",
    "temp_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#### Rain Preparation\n",
    "\n",
    "All 27 Rain CSVs are processed into rain.df and rain.csv.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Load the 'pr' data from the '../data' directory and create a dataframe 'rain_df'\n",
    "# with the 'Rain_mm/yr' data. \n",
    "rain_df = combine('../data', 'pr', 'Rain_mm/yr')\n",
    "\n",
    "# Display the first few rows of the 'rain_df' dataframe.\n",
    "rain_df.head()\n",
    "\n",
    "# Save the 'rain_df' dataframe to a CSV file in the '../data/processed' directory, \n",
    "# with the filename 'rain.csv', and exclude the index column from the output.\n",
    "rain_df.to_csv('../data/processed/rain.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the 'rain_df' dataframe again.\n",
    "rain_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only data from 2000 and later\n",
    "beef_df = beef_df[beef_df['Year'] >= 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=beef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the column titles\n",
    "cols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanp() # scans the processed folder in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Input/Output:\n",
    "- readr()\n",
    "- scan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning:\n",
    "- camel()\n",
    "- pascal()\n",
    "- snake()\n",
    "- clean_df()\n",
    "- eu()\n",
    "- now2()\n",
    "- split_file_name()\n",
    "- splitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration:\n",
    "- filter_col_by_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "- eu()\n",
    "- transform\n",
    "- get_annual_aggregates()\n",
    "- get_dfs()\n",
    "- get_multi_index_df()\n",
    "- get_ranking_df()\n",
    "- pivot_table_aggregate()\n",
    "- prepare_wealth_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split\n",
    "The split function takes a pandas DataFrame df and a column name col as input, and returns a dictionary where each key corresponds to a unique value in the specified column, and each value is a DataFrame containing all rows with that unique value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "#### Split\n",
    "The split function takes a pandas DataFrame df and a column name col as input, and returns a dictionary where each key corresponds to a unique value in the specified column, and each value is a DataFrame containing all rows with that unique value.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def split(df: pd.DataFrame, col: str) -> dict:\n",
    "    \"\"\"\n",
    "    \n",
    " \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to split.\n",
    "        col (str): The name of the column to group by.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where each key corresponds to a unique value in the specified column,\n",
    "        and each value is a DataFrame containing all rows with that unique value.\n",
    "    \"\"\"\n",
    "    dfs = dict(tuple(df.groupby(col)))\n",
    "    return dfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def now2(df):\n",
    "    \"\"\"\n",
    "    Filter to 'Year' >= 2000.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame to filter.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: The filtered DataFrame.\n",
    "    \"\"\"\n",
    "    year_min = 2000\n",
    "    return df[df['Year'] >= year_min]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Combination:\n",
    "- merge_dfs()\n",
    "- combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Snake\n",
    "\n",
    "\n",
    "def snake(text, default='default'):\n",
    "    \"\"\"\n",
    "    Converts a given string to snake_case by replacing any whitespace characters with underscores,\n",
    "    converting to all lowercase, and removing any non-alphanumeric characters from the beginning and end.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The string to convert to snake_case.\n",
    "        default (str): The default value to return if the input text is empty.\n",
    "\n",
    "    Returns:\n",
    "        str: The resulting string in snake_case format, or the default value if the input text is empty.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return default\n",
    "    # Convert to string and replace any non-alphanumeric characters at the beginning and end with an empty string\n",
    "    text = re.sub(r'^\\W+|\\W+$', '', str(text))\n",
    "    # Replace any period symbols with underscores\n",
    "    text = text.replace('.', '')\n",
    "    # Replace any other non-alphanumeric characters with empty strings\n",
    "    text = re.sub(r'\\W+', '_', text)\n",
    "    # Convert to all lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Example usage:\n",
    "text = \"This is a text with periods. (And other characters.)\"\n",
    "result = snake(text)\n",
    "print(result)  # Output: \"this_is_a_text_with_periods_and_other_characters\"\n",
    "\n",
    "\n",
    "# snake('does snake Work')\n",
    "\n",
    "# snake('                  ')\n",
    "# snake('                  ')\n",
    "# snake('                  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snake('\"This is a text with periods. (And other characters.)\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Pascal\n",
    "The 'pascal' naming function takes in a string as input and converts it to a PascalCase format. PascalCase is a naming convention where the first letter of each word is capitalized, and there are no spaces or separators between the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pascal(string):\n",
    "    \"\"\"\n",
    "    Convert a space- or snake-separated string to PascalCase.\n",
    "\n",
    "    Parameters:\n",
    "        string (str): The input string to convert to PascalCase.\n",
    "\n",
    "    Returns:\n",
    "        str: The input string in PascalCase format.\n",
    "\n",
    "    \"\"\"\n",
    "    # Replace any underscores with spaces\n",
    "    string = string.replace(\"_\", \" \")\n",
    "    # Capitalize the first letter of each word\n",
    "    words = string.title()\n",
    "    # Remove any remaining spaces\n",
    "    words = words.replace(\" \", \"\")\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#### Camel\n",
    "\n",
    "Camel case is a naming convention in which each word in a compound word is capitalized, except for the first word which is in lower case. It is commonly used in programming languages for naming variables and functions.\n",
    "\n",
    "handles both snake_case and space-separated strings\n",
    "\"\"\"\n",
    "def camel(string):\n",
    "    \"\"\"\n",
    "    Convert a space-separated or snake_case string to camelCase.\n",
    "\n",
    "    Parameters:\n",
    "        string (str): The string to convert.\n",
    "\n",
    "    Returns:\n",
    "        str: The converted string in camelCase.\n",
    "    \"\"\"\n",
    "    # Replace underscores with spaces and split the string into a list of words\n",
    "    words = string.replace(\"_\", \" \").split()\n",
    "    # Convert the first word to lowercase and capitalize all subsequent words\n",
    "    camel_cased = [words[0].lower()] + [word.capitalize() for word in words[1:]]\n",
    "    # Concatenate the words together and return the resulting string\n",
    "    return \"    \" + ''.join(camel_cased) + \"    \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#### Title \n",
    "The 'title' naming convention is where each word starts\n",
    "with a capital letter, except for prepositions and conjunctions, which start with a lowercase letter. \n",
    "The function takes a string as input and converts it to title case, \n",
    "where the first letter of each non-conjunction/preposition word is capitalized, and all other letters are lowercase.\n",
    "It achieves this by splitting the input string into a list of words, identifying which words are prepositions or conjunctions based on a predefined list, and then capitalizing the first letter of all other words while converting prepositions and conjunctions to lowercase. The resulting list of processed words is then joined back into a single string with proper spacing and returned.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def title(sentence):\n",
    "    \"\"\"\n",
    "    Takes a string and converts it to title case, where the first letter of each\n",
    "    non-conjunction/preposition word is capitalized, and all other letters are lowercase.\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): The string to convert to title case.\n",
    "        \n",
    "    Returns:\n",
    "        str: The input string converted to title case.\n",
    "    \"\"\"\n",
    "    # Define a list of common prepositions and conjunctions\n",
    "    prepositions_conjunctions = ['a', 'this', 'an', 'the', 'and', 'but', 'or', 'for', 'has', 'nor', 'on', 'at', 'to', 'from', 'by', 'over', 'under', 'in', 'out', 'of']\n",
    "    # Split the input string into a list of words\n",
    "    words = sentence.split()\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        # If the word is not a preposition or conjunction, capitalize the first letter and lowercase the rest\n",
    "        if word.lower() not in prepositions_conjunctions:\n",
    "            processed_words.append(word.capitalize())\n",
    "        # If the word is a preposition or conjunction, convert to lowercase\n",
    "        else:\n",
    "            processed_words.append(word.lower())\n",
    "    # Join the list of processed words into a single string, with proper spacing\n",
    "    output = \" \".join(processed_words)\n",
    "    # Remove any leading/trailing whitespace and add some padding\n",
    "    return \"     \" + re.sub('\\s+', ' ', output.strip()) + \"     \"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_count(string):\n",
    "    \"\"\"\n",
    "    Count the number of characters in a string.\n",
    "\n",
    "    Parameters:\n",
    "    - string (str): The string to count characters in.\n",
    "\n",
    "    Returns:\n",
    "    - int: The number of characters in the string.\n",
    "    \"\"\"\n",
    "    return len(string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Scanners,  Readers and Writers\n",
    "#### Scanners\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def scan(folder_path=\"../\"):\n",
    "    \"\"\"Scans the specified folder and prints contents information.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): The path to the folder to scan. Default is the root directory.\n",
    "\n",
    "    Returns:\n",
    "        Prints out contents information of the specified folder.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        contents = os.listdir(folder_path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Directory not found: {}\".format(folder_path))\n",
    "        return\n",
    "    except OSError:\n",
    "        print(\"Invalid folder path: {}\".format(folder_path))\n",
    "        return\n",
    "    print(\"Contents of the folder '{}':\".format(folder_path))\n",
    "    for item in contents:\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        if os.path.isfile(item_path):\n",
    "            size = os.path.getsize(item_path) // 1024  # Convert to KB\n",
    "            print(\"{:30} {:10,} KB\".format(item, size))\n",
    "        else:\n",
    "            print(\"{} (directory)\".format(item))\n",
    "\n",
    "# scan('../../images')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scann():\n",
    "    \"\"\"Scans the raw data folder and prints contents information.\n",
    "\n",
    "    Parameters:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        Prints out contents information of the raw data folder.\n",
    "    \"\"\"\n",
    "    folder_path = \"../notebooks\"\n",
    "    try:\n",
    "        contents = os.listdir(folder_path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Directory not found\")\n",
    "        return\n",
    "    except OSError:\n",
    "        print(\"Invalid folder path\")\n",
    "        return\n",
    "    print(\"Contents of the folder '{}':\".format(folder_path))\n",
    "    for item in contents:\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        if os.path.isfile(item_path):\n",
    "            size = os.path.getsize(item_path)\n",
    "            modified_time = datetime.datetime.fromtimestamp(os.path.getmtime(item_path)).strftime('%Y-%m-%d %H:%M')\n",
    "            print(\"{:30} {:10} {}\".format(item, size, modified_time))\n",
    "        else:\n",
    "            print(\"{} (directory)\".format(item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scanr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Readers\n",
    "\n",
    "'read_csv' is a function in the Pandas library for reading in CSV (Comma Separated Values) files into a DataFrame. It is a flexible function that can handle a variety of input formats, including different delimiters, encodings, and line endings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(filename, df_name, folder_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file from the specified folder and returns a pandas DataFrame\n",
    "    with the specified name.\n",
    "\n",
    "    Parameters:\n",
    "        filename (str): The name of the CSV file to be read.\n",
    "        df_name (str): The name to be assigned to the resulting DataFrame.\n",
    "        folder_path (str): The path of the folder containing the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame created from the data in the CSV file with\n",
    "        the specified name.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(folder_path, f'{filename}.csv')\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.name = df_name\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readr(filename, df_name):\n",
    "    \"\"\"\n",
    "    Reads a CSV file from  the raw data folder and returns a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        filename (str): base name of CSV file to be read.\n",
    "        df_name (str): The DataFrame name to be assigned \n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame created from the data in the CSV file with\n",
    "        the specified name.\n",
    "    \"\"\"\n",
    "    file_path = '../data/raw/' + filename + '.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.name = df_name\n",
    "    return df\n",
    "# readr('land_use','land_use_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readp(filename, df_name):\n",
    "    \"\"\"\n",
    "    Reads a CSV file from the specified file path in the processed folder and returns a pandas DataFrame\n",
    "    with the specified name.\n",
    "    \n",
    "    Parameters:\n",
    "        filename (str): The name of the CSV file to be read.\n",
    "        df_name (str): The name to be assigned to the resulting DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame created from the data in the CSV file with\n",
    "        the specified name.\n",
    "    \"\"\"\n",
    "    file_path = f'../data/processed/{filename}.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.name = df_name\n",
    "    return df\n",
    "# df=readp('missing','missing_df')\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(file_name: str) -> Tuple[Dict[str, pd.DataFrame], List[str]]:\n",
    "    \"\"\"\n",
    "    Splits a CSV file into multiple dataframes based on the unique values in the 'Element' column.\n",
    "    \n",
    "    Parameters:\n",
    "        file_name (str): The name of the CSV file to read in.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[Dict[str, pd.DataFrame], List[str]]: A tuple containing a dictionary where each key corresponds\n",
    "        to a unique value in the 'Element' column, and each value is a dataframe containing all rows with that\n",
    "        unique value, and a list of unique values in the 'Element' column.\n",
    "    \"\"\"\n",
    "    if not file_name.endswith('.csv'):\n",
    "        raise ValueError('Input file must be a .csv file')\n",
    "    \n",
    "    # Load the specified dataframe\n",
    "    df = pd.read_csv(f'../data/raw/{file_name}')\n",
    "    \n",
    "    # Group the dataframe by the 'Element' column\n",
    "    dfs = dict(tuple(df.groupby('Element')))\n",
    "    \n",
    "    # Get the unique values in the 'Element' column\n",
    "    elements = list(df['Element'].unique())\n",
    "    \n",
    "    return dfs, elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_elementr(file_name: str) -> Tuple[Dict[str, pd.DataFrame], List[str]]:\n",
    "    \"\"\"\n",
    "    Splits a CSV file into multiple dataframes based on the unique values in the 'Element' column.\n",
    "    \n",
    "    Parameters:\n",
    "        file_name (str): The name of the CSV file to read in.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[Dict[str, pd.DataFrame], List[str]]: A tuple containing a dictionary where each key corresponds\n",
    "        to a unique value in the 'Element' column, and each value is a dataframe containing all rows with that\n",
    "        unique value, and a list of unique values in the 'Element' column.\n",
    "    \"\"\"\n",
    "    # Load the specified dataframe\n",
    "    df = pd.read_csv(f'../data/raw/{file_name}')\n",
    "    \n",
    "    # Group the dataframe by the 'Element' column\n",
    "    dfs = dict(tuple(df.groupby('Element')))\n",
    "    \n",
    "    # Get the unique values in the 'Element' column\n",
    "    elements = list(df['Element'].unique())\n",
    "    \n",
    "    return dfs, elements\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_by_element(df: pd.DataFrame) -> Tuple[Dict[str, pd.DataFrame], List[str]]:\n",
    "    \"\"\"\n",
    "    Splits a DataFrame into multiple dataframes based on the unique values in the 'Element' column.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to split.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[Dict[str, pd.DataFrame], List[str]]: A tuple containing a dictionary where each key corresponds\n",
    "        to a unique value in the 'Element' column, and each value is a dataframe containing all rows with that\n",
    "        unique value, and a list of unique values in the 'Element' column.\n",
    "    \"\"\"\n",
    "    # Group the dataframe by the 'Element' column\n",
    "    dfs = dict(tuple(df.groupby('Element')))\n",
    "    \n",
    "    # Get the unique values in the 'Element' column\n",
    "    elements = list(df['Element'].unique())\n",
    "    \n",
    "    return dfs, elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupdf(df, column_name):\n",
    "    # Group the dataframe by the specified column\n",
    "    dfs = dict(tuple(df.groupby(column_name)))\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Delete\n",
    "\n",
    "In this code, we use the os module to delete a file at the specified file path. We first check if the file exists using the os.path.exists() function. If the file exists, we delete it using the os.remove() function. If the file does not exist, we print a message indicating that the file was not found.\n",
    "\n",
    "Note that this code permanently deletes the file, so you should use it with caution. Once a file is deleted, it cannot be easily recovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def delete(file_name):\n",
    "    file_path = os.path.join(\"..\", \"data\", \"raw\", file_name)\n",
    "    expected_ext = \".csv\"\n",
    "    if not file_path.endswith(expected_ext):\n",
    "        print(\"Error: Invalid file extension. File extension must be .csv.\")\n",
    "    elif os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(f\"{file_name} deleted successfully\")\n",
    "    else:\n",
    "        print(f\"{file_name} not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename\n",
    "\n",
    "This function first constructs the file_path by joining the ../data/raw directory with the given file_name. It then sets the expected file extension to .csv. The function then checks if the file_path ends with the expected file extension. If it doesn't, the function prints an error message. If it does, the function checks if the file exists at file_path, and if it does, it removes it and prints a success message. If the file doesn't exist, the function prints a \"not found\" message. like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(old_filename, new_filename):\n",
    "    old_file_path = os.path.join(\"..\", \"data\", old_filename)\n",
    "    new_file_path = os.path.join(\"..\", \"data\", new_filename)\n",
    "    try:\n",
    "        os.rename(old_file_path, new_file_path)\n",
    "        print(f\"{old_filename} renamed to {new_filename} successfully\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{old_filename} not found\")\n",
    "    except FileExistsError:\n",
    "        print(f\"A file with the name {new_filename} already exists\")\n",
    "    except OSError:\n",
    "        print(\"Invalid file path or name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(input_str, find_str, replace_str):\n",
    "    output_str = re.sub(find_str, replace_str, input_str)\n",
    "    \n",
    "    if output_str == input_str:\n",
    "        warnings.warn(\"Replacement unsuccessful: '{}' not found in input string.\".format(find_str))\n",
    "    \n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  tabler\n",
    "\n",
    "\"\"\"The code defines a function tabler that generates an HTML table with information on the files in a given folder and\n",
    "adds a section header that contains the directory path \n",
    "\"\"\"\n",
    "\n",
    "def tabler(folder_path):\n",
    "    \"\"\"\n",
    "    Generate an HTML table with information on files in a given folder.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): The path to the folder containing the files.\n",
    "\n",
    "    Returns:\n",
    "    - str: The HTML code for the table.\n",
    "    \"\"\"\n",
    "    # Get the contents of the folder\n",
    "    try:\n",
    "        contents = os.listdir(folder_path)\n",
    "    except FileNotFoundError:\n",
    "        return \"Directory not found\"\n",
    "    except OSError:\n",
    "        return \"Invalid folder path\"\n",
    "\n",
    "    # Create the section header\n",
    "    header = f\"### {folder_path}\\n\\n\"\n",
    "\n",
    "    # Create the table header\n",
    "    table = '<table style=\"font-size:100%\"><thead><tr><th>File Name</th><th>Size</th><th>Modified Time</th></tr></thead><tbody>'\n",
    "\n",
    "    # Add a row for each file\n",
    "    for item in contents:\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        if os.path.isfile(item_path):\n",
    "            # Get the file size and modified time\n",
    "            size_bytes = os.path.getsize(item_path)\n",
    "            size_kb = size_bytes / 1024\n",
    "            size_str = '{:,.2f} KB'.format(size_kb)\n",
    "            modified_time = datetime.datetime.fromtimestamp(os.path.getmtime(item_path)).strftime('%Y-%m-%d %H:%M')\n",
    "            # Add a row to the table\n",
    "            table += '<tr><td>{}</td><td>{}</td><td>{}</td></tr>'.format(item, size_str, modified_time)\n",
    "\n",
    "    # Close the table\n",
    "    table += '</tbody></table>'\n",
    "\n",
    "    return header + table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beef(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns a Pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): The path to the CSV file to read.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The resulting DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "- eu(df)\n",
    "- now2(df)\n",
    "- split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  String Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File System Operations\n",
    "\n",
    "\n",
    "These functions are responsible for performing various operations on the file system.\n",
    "scan(): Scans a specified folder and prints contents information.\n",
    "tabler(): Generates an HTML table with information on files in a given folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### eu\n",
    "def eu(df):\n",
    "    \"\"\"\n",
    "    Filter a pandas DataFrame to include only the rows where the 'Area' column contains values that match the countries in the European Union.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame to filter.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: The filtered DataFrame.\n",
    "    \"\"\"\n",
    "    country_list = ['Austria', 'Belgium', 'Bulgaria', 'Croatia', 'Cyprus', 'Czechia', 'Denmark', \n",
    "                    'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Hungary', 'Ireland', 'Italy', \n",
    "                    'Latvia', 'Lithuania', 'Luxembourg', 'Malta', 'Netherlands', 'Poland', 'Portugal', 'Romania', \n",
    "                    'Slovakia', 'Slovenia', 'Spain', 'Sweden']\n",
    "    return df[df['Area'].isin(country_list)]\n",
    "\n",
    "# df=readr('meat','df')\n",
    "# df=eu(df)\n",
    "# df\n",
    "++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def now(df, year_min):\n",
    "    \"\"\"\n",
    "    Filter to 'Year'>.\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame to filter.\n",
    "    - year_min (int): The minimum year to include in the filtered DataFrame.\n",
    "    Returns:\n",
    "    - pandas.DataFrame: The filtered DataFrame.\n",
    "    \"\"\"\n",
    "    return df[df['Year'] >= year_min]\n",
    "\n",
    "# df=readr('meat','df')\n",
    "# df = now(df, 2015)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and  comparison of Ireland's beef sector with other  EU contries\n",
    "\n",
    "![image1](../images/tu04.png)\n",
    "\n",
    "<span style=\"font-size: 24px;\">                 </span>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we carry out the first 6 stages in the followning list@\n",
    "\n",
    "1. Reading - export, import, trade imbalance, arable production, animal stock\n",
    "2. Cleaning\n",
    "3. Transformation\n",
    "4. Splitting\n",
    "5. Aggregation\n",
    "6. Analysis\n",
    "7. Visualization\n",
    "8. Modeling and Machine Learning\n",
    "9. Forecasting\n",
    "10. Sentiment Analysis\n",
    "11. Evidence Based Recommendations\n",
    "12. Process Rationale\n",
    "13. Ireland as your baseline.\n",
    "\n",
    "\n",
    "## Modules Functions Libraries and How to Use\n",
    "\n",
    "Before starting the exploratory data analysis (EDA), make sure to execute all necessary module imports, libraries, and functions. This will ensure all  required dependencies and tools to perform analysis are operational.\n",
    "To execute all necessary module imports, libraries, and functions before starting the exploratory data analysis (EDA) \n",
    "**Restart & run all** as convention of dependancy order was broken for organisational purposes! On my part that is! Sorry!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Reading\n",
    "2. Data Cleaning\n",
    "3. Data Transformation\n",
    "4. Data Splitting\n",
    "5. Data Aggregation\n",
    "6. Data Analysis\n",
    "7. Data Visualization\n",
    "8. Modeling and Machine Learning\n",
    "9. Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAOSTAT Data Domains \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"../images/we16.png\" alt=\"image7\" width=\"80%\">\n",
    "\n",
    "[<span style=\"font-size: 18px;\">Figure 2:Data Domain Table view of FAOSTAT</span>\n",
    "](https://www.fao.org/faostat/en/#data/domains_table)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The [FAOSTAT Data Domains](https://www.fao.org/faostat/en/#data/domains_table)  are organised as follows:\n",
    "\n",
    "  -  Production: Production of crops and livestock products, including production indices and the value of agricultural production.\n",
    "\n",
    "  - Food Security and Nutrition: Information on SDG indicators related to food security and nutrition and food balances.\n",
    "\n",
    "  - Trade: Including detailed trade matrices, trade indices, and updates on related data.\n",
    "\n",
    "  - Prices: Producer and   consumer price indices, deflators, and exchange rates.\n",
    "\n",
    "  - Land, Inputs and Sustainability:Land use, land cover, inputs, including fertilizers and manure and pesticides.\n",
    "  \n",
    "  - Population and Employment: Annual population including those specific to agriculture and rural areas.\n",
    "\n",
    "  - Investment: Government expenditure, credit to agriculture, foreign direct investment, and country investment statistics.\n",
    "\n",
    "  - Macro-Economic Indicators: Such as capital stock.\n",
    "\n",
    "  - Food Value Chain: This domain provides information on the value shares of the food industry and primary factors.\n",
    "\n",
    "  - Climate Change: Emissions, crop residues, forests, and other indicators related to climate change.\n",
    "\n",
    "  - Forestry: Forestry production and trade, as well as forestry trade flows.\n",
    "\n",
    "  - SDG Indicators: The Sustainable Development Goals (SDGs) are a set of 17 goals established by the United Nations in 2015.\n",
    "\n",
    "  - World Census of Agriculture: This domain provides structural data from agricultural censuses taken around the world\n",
    "\n",
    "  - Discontinued archives and data series: This includes data on indicators from surveys and research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate  Data Preparation \n",
    "\n",
    "<img src=\"../images/tu03.png\" alt=\"image5\" width=\"50%\">\n",
    "<span style=\"font-size: 24px;\">                  </span>\n",
    " Only two attributes are taken from the CCKP database: Mean_Temperature and Precipitation.\n",
    "\n",
    "[The CCKP website](https://climateknowledgeportal.worldbank.org/)\n",
    " is a  resource for information on the impacts of climate change and the actions taken to address these impacts. While this is outside the remit of this project the CCKP also provides access to global data on a historical  basis for the **Mean_Temperature** and **Precipitation** at the  country-by-country level  on both monthly and yearly aggregates. While **humidity** is also a known influential predictor variable these two should have a statistically significant imapct on our predictive modelling. Spatial data is provided as a global NetCDF file, with Climatology, Timeseries and Heatplot data is provided as a CSV file.\n",
    "\n",
    "Climate conditions, such as average temperature and rainfall (precipitation ) can greatly affect the growth and health of cattle. Precipitation and temperature predictor variables were  retrieved  but they were   aggragated by country and this necessitated  the **cckp** and  **combine**  functions for data wrangling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  About FAOSTAT\n",
    "\n",
    "<img src=\"../images/tu02.png\" alt=\"image5\" width=\"50%\">\n",
    "\n",
    "<span style=\"font-size: 24px;\">                  </span>\n",
    "FAOSTAT is a comprehensive database maintained by the Food and Agriculture Organization of the United Nations (FAO), providing timely, reliable data on agriculture, food, and nutrition for over 200 countries. Its information is used to inform decision-making, policy formulation, and research in the field, covering topics such as production, trade, and fertilizer use. FAOSTAT is a valuable resource for governments, organizations, researchers, and the public, informing policy and interventions to enhance food security and reduce poverty.\n",
    "\n",
    "#### Licencing \n",
    "All datasets from the [FAOSTAT](https://www.fao.org/faostat/en/#home) are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 IGO [(CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/). Source: FAOSTAT (2023). Time Series datasets.\n",
    "<img src=\"../images/tu06.png\" alt=\"image5\" width=\"50%\">\n",
    "<span style=\"font-size: 24px;\">                  </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "####   CCKP Data  and an initial bit of EDA\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "  <img src=\"../images/we28.png\" alt=\"image19\" style=\"width: 30%;\">\n",
    "  <img src=\"../images/we29.png\" alt=\"image20\" style=\"width: 30%;\">\n",
    "    <img src=\"../images/we30.png\" alt=\"image20\" style=\"width: 30%;\">\n",
    "</div>\n",
    "\n",
    "<span style=\"font-size: 18px;\">Figure 3:Time Series Data downloaded for 27 EU countries from  CCKP site </span>\n",
    "\n",
    "\n",
    "To maintain consistency with the FAO data, annual and not monthly time series  aggregates were taken from the Climatic Research Unit (CRU) dataset for **precipitation** and   **mean-temperature**. These datasets are provided by the CRU TS 4.04 dataset, a gridded climate dataset produced by the Climatic Research Unit (CRU) at the University of East Anglia in the United Kingdom. In the statistics section, range, variance, and standard deviation of monthly data may be revisited for insights.\n",
    "\n",
    "The file names and folder names of the CCKP data used in this project are tabulated below.\n",
    "\n",
    "<span style=\"font-size: 24px;\">Table : Table shows Time Series data filenames and folders  for 27 EU countries from  CCKP site </span>\n",
    "\n",
    "\n",
    "\n",
    "| Country        | Code | TasAnnual (Folder with Tempature data)                              | PrAnnual   (Folder with Precipitation Data)                        |\n",
    "|:--------------:|:----:|:--------------------------------------:|:---------------------------------:|\n",
    "| Albania        | ALB  | tas_timeseries_annual_cru_1901-2021_ALB.csv | pr_timeseries_annual_cru_1901-2021_ALB.csv |\n",
    "| Andorra        | AND  | tas_timeseries_annual_cru_1901-2021_AND.csv | pr_timeseries_annual_cru_1901-2021_AND.csv |\n",
    "| Austria        | AUT  | tas_timeseries_annual_cru_1901-2021_AUT.csv | pr_timeseries_annual_cru_1901-2021_AUT.csv |\n",
    "| Belarus        | BLR  | tas_timeseries_annual_cru_1901-2021_BLR.csv | pr_timeseries_annual_cru_1901-2021_BLR.csv |\n",
    "| Belgium        | BEL  | tas_timeseries_annual_cru_1901-2021_BEL.csv | pr_timeseries_annual_cru_1901-2021_BEL.csv |\n",
    "| Bosnia and Herzegovina | BIH  | tas_timeseries_annual_cru_1901-2021_BIH.csv | pr_timeseries_annual_cru_1901-2021_BIH.csv |\n",
    "| Bulgaria       | BGR  | tas_timeseries_annual_cru_1901-2021_BGR.csv | pr_timeseries_annual_cru_1901-2021_BGR.csv |\n",
    "| Croatia        | HRV  | tas_timeseries_annual_cru_1901-2021_HRV.csv | pr_timeseries_annual_cru_1901-2021_HRV.csv |\n",
    "| Cyprus         | CYP  | tas_timeseries_annual_cru_1901-2021_CYP.csv | pr_timeseries_annual_cru_1901-2021_CYP.csv |\n",
    "| Czech Republic | CZE  | tas_timeseries_annual_cru_1901-2021_CZE.csv | pr_timeseries_annual_cru_1901-2021_CZE.csv |\n",
    "| Denmark        | DNK  | tas_timeseries_annual_cru_1901-2021_DNK.csv | pr_timeseries_annual_cru_1901-2021_DNK.csv |\n",
    "| Estonia        | EST  | tas_timeseries_annual_cru_1901-2021_EST.csv | pr_timeseries_annual_cru_1901-2021_EST.csv |\n",
    "| Finland        | FIN  | tas_timeseries_annual_cru_1901-2021_FIN.csv | pr_timeseries_annual_cru_1901-2021_FIN.csv |\n",
    "| France         | FRA  | tas_timeseries_annual_cru_1901-2021_FRA.csv | pr_timeseries_annual_cru_1901-2021_FRA.csv |\n",
    "| Germany        | DEU  | tas_timeseries_annual_cru_1901-2021_DEU.csv | pr_timeseries_annual_cru_1901-2021_DEU.csv |\n",
    "| Gibraltar      | GIB  | tas_timeseries_annual_cru_1901-2021_GIB.csv | pr_timeseries_annual_cru_1901-2021_GIB.csv |\n",
    "| Greece | GRC | tas_timeseries_annual_cru_1901-2021_GRC.csv | pr_timeseries_annual_cru_1901-2021_GRC.csv |\n",
    "| Croatia | HRV | tas_timeseries_annual_cru_1901-2021_HRV.csv | pr_timeseries_annual_cru_1901-2021_HRV.csv |\n",
    "| Hungary | HUN | tas_timeseries_annual_cru_1901-2021_HUN.csv | pr_timeseries_annual_cru_1901-2021_HUN.csv |\n",
    "| Ireland | IRL | tas_timeseries_annual_cru_1901-2021_IRL.csv | pr_timeseries_annual_cru_1901-2021_IRL.csv |\n",
    "| Italy | ITA | tas_timeseries_annual_cru_1901-2021_ITA.csv | pr_timeseries_annual_cru_1901-2021_ITA.csv |\n",
    "| Lithuania | LTU | tas_timeseries_annual_cru_1901-2021_LTU.csv | pr_timeseries_annual_cru_1901-2021_LTU.csv |\n",
    "| Luxembourg | LUX | tas_timeseries_annual_cru_1901-2021_LUX.csv | pr_timeseries_annual_cru_1901-2021_LUX.csv |\n",
    "| Latvia | LVA | tas_timeseries_annual_cru_1901-2021_LVA.csv | pr_timeseries_annual_cru_1901-2021_LVA.csv |\n",
    "| Malta | MLT | tas_timeseries_annual_cru_1901-2021_MLT.csv | pr_timeseries_annual_cru_1901-2021_MLT.csv |\n",
    "| Netherlands | NLD | tas_timeseries_annual_cru_1901-2021_NLD.csv | pr_timeseries_annual_cru_1901-2021_NLD.csv |\n",
    "| Poland | POL | tas_timeseries_annual_cru_1901-2021_POL.csv | pr_timeseries_annual_cru_1901-2021_POL.csv |\n",
    "| Portugal | PRT | tas_timeseries_annual_cru_1901-2021_PRT.csv | pr_timeseries_annual_cru_1901-2021_PRT.csv |\n",
    "| Romania | ROU | tas_timeseries_annual_cru_1901-2021_ROU.csv | pr_timeseries_annual_cru_1901-2021_ROU.csv |\n",
    "| Slovakia | SVK | tas_timeseries_annual_cru_1901-2021_SVK.csv | pr_timeseries_annual_cru_1901-2021_SVK.csv |\n",
    "| Slovenia | SVN | tas_timeseries_annual_cru_1901-2021_SVN.csv | pr_timeseries_annual_cru_1901-2021_SVN.csv |\n",
    "| Sweden | SWE | tas_timeseries_annual_cru_1901-2021_SWE.csv | pr_timeseries_annual_cru_1901-2021_SWE.csv |\n",
    "\n",
    "\n",
    "All datasets from the CCKP are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO). \n",
    "Source: CCKP (2023). Time Series datasets. Retrieved from [https://climateknowledgeportal.worldbank.org/download-data]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readcattle():\n",
    "    \"\"\"\n",
    "    Reads in the 'live_animale_cattle_stock_eu_1961_2021.csv' file from the '../data/raw/' directory and returns a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    data_path = '../data/raw/live_animale_cattle_stock_eu_1961_2021.csv'\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readcattle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions and techniques:\n",
    "\n",
    "Data Cleaning:\n",
    "\n",
    "df.dropna()\n",
    "df.fillna()\n",
    "df.clip()\n",
    "df.replace()\n",
    "df.drop_duplicates()\n",
    "df.drop_duplicates()\n",
    "df.fillna()\n",
    "df.merge()\n",
    "df.pivot()\n",
    "df.rename()\n",
    "df.query()\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df['column_name'].interpolate(inplace=True)\n",
    "os.listdir('data')\n",
    "Data Wrangling:\n",
    "\n",
    "df.melt()\n",
    "df.pivot()\n",
    "df.stack()\n",
    "df.unstack()\n",
    "df.astype()\n",
    "df.get()\n",
    "df.apply()\n",
    "pd.crosstab()\n",
    "pd.concat()\n",
    "df.rename()\n",
    "df.replace()\n",
    "df.sort_values()\n",
    "df.transform()\n",
    "Data Exploration:\n",
    "\n",
    "df.info()\n",
    "df.describe()\n",
    "df.value_counts()\n",
    "Data Visualization:\n",
    "\n",
    "plotly.plot()\n",
    "seaborn.plot()\n",
    "bokeh.plot()\n",
    "ggplot.plot()\n",
    "matplotlib.plot()\n",
    "plot.plot()\n",
    "holoviews.plot()\n",
    "Data Transformation:\n",
    "\n",
    "df.log()\n",
    "df.exp()\n",
    "df.normalize()\n",
    "df.scale()\n",
    "df.power()\n",
    "df.abs()\n",
    "df.rescale()\n",
    "df.subtract()\n",
    "df.divide()\n",
    "df.add()\n",
    "df.expit()\n",
    "df.cumsum()\n",
    "Feature Engineering:\n",
    "\n",
    "df.discretize()\n",
    "df.binarize()\n",
    "df.rank()\n",
    "df.dummies()\n",
    "df.group_enc()\n",
    "df.interactions()\n",
    "df.frequency()\n",
    "df.scaling/discretize()\n",
    "df.non-linear_trans()\n",
    "Time Series Analysis:\n",
    "\n",
    "df.pct()\n",
    "df.shift()\n",
    "df.diff()\n",
    "df.pct_change()\n",
    "df.autocorr()/df.pacf()\n",
    "df.rolling()\n",
    "df.forecast()\n",
    "df.rolling_window()\n",
    "Statistical Analysis:\n",
    "\n",
    "df.describe()\n",
    "df.skew()\n",
    "df.kurtosis()\n",
    "df.corr()\n",
    "stats.ttest_ind()\n",
    "statsmodels.stats.ztest()\n",
    "stats.chi2_contingency()\n",
    "stats.f_oneway()\n",
    "statsmodels.formula.api.ols()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Data Cleaning           |\n",
    "| -----------------------|\n",
    "| df.dropna()            |\n",
    "| df.fillna()            |\n",
    "| df.clip()              |\n",
    "| df.replace()           |\n",
    "| pd.cut()               |\n",
    "| df.drop_duplicates()   |\n",
    "| df.drop_duplicates()   |\n",
    "| df.fillna()            |\n",
    "| df.merge()             |\n",
    "| df.pivot()             |\n",
    "| df.rename()            |\n",
    "| df.query()             |\n",
    "| df.dropna(axis=0, inplace=True)  |\n",
    "| df['column_name'].interpolate(inplace=True) |\n",
    "| os.listdir('data')     |\n",
    "| N/A                    |\n",
    "\n",
    "| Data Wrangling          |\n",
    "| ------------------------|\n",
    "| df.melt()               |\n",
    "| df.pivot()              |\n",
    "| df.stack()              |\n",
    "| df.unstack()            |\n",
    "| df.astype()             |\n",
    "| df.apply()              |\n",
    "| df.groupby()            |\n",
    "| pd.crosstab()           |\n",
    "| pd.concat()             |\n",
    "| df.replace()            |\n",
    "| df.rename()             |\n",
    "| df.sort_values()        |\n",
    "| df.transform()          |\n",
    "\n",
    "| Data Exploration         |\n",
    "| -------------------------|\n",
    "| df.info()                |\n",
    "| df.describe()            |\n",
    "| df.describe()            |\n",
    "| df.value_counts()        |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "\n",
    "| Data Visualization       |\n",
    "| -------------------------|\n",
    "| plotly.plot()            |\n",
    "| seaborn.plot()           |\n",
    "| ggplot.plot()            |\n",
    "| matplotlib.plot()        |\n",
    "| plot.plot()              |\n",
    "| holoviews.plot()         |\n",
    "| bokeh.plot()             |\n",
    "| plotly.plot()            |\n",
    "| seaborn.plot()           |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "\n",
    "| Data Transformation       |\n",
    "| --------------------------|\n",
    "| df.log()                  |\n",
    "| df.exp()                  |\n",
    "| df.scale()                |\n",
    "| df.normalize()            |\n",
    "| df.sqrt()                 |\n",
    "| df.abs()                  |\n",
    "| df.abs()                  |\n",
    "| df.divide()               |\n",
    "| df.subtract()             |\n",
    "| df.multiply()             |\n",
    "| df.add()                  |\n",
    "| df.expit()                |\n",
    "| df.cumsum()               |\n",
    "| N/A                       |\n",
    "\n",
    "| Feature Engineering       |\n",
    "| --------------------------|\n",
    "| df.discretize()           |\n",
    "| df.binarize()             |\n",
    "| df.dummies()              |\n",
    "| df.group_enc()            |\n",
    "| df.interactions()         |\n",
    "| df.pca()/df.ica()         |\n",
    "| df.non-linear_trans()     |\n",
    "| df.scaling/discretize()   |\n",
    "| df.rolling_window()       |\n",
    "| N/A                       |\n",
    "\n",
    "| Time Series Analysis       |\n",
    "| --------------------------|\n",
    "| df.pct()                  |\n",
    "| df.shift()                |\n",
    "| df.count()                |\n",
    "| df.rank()                 |\n",
    "| df.zscore()               |\n",
    "| df.frequency()            |\n",
    "| df.rolling()              |\n",
    "| df.autocorr()/df.pacf()   |\n",
    "| N/A                       |\n",
    "| N/A                       |\n",
    "| df.pct_change()           |\n",
    "| df.forecast()             |\n",
    "| N/A                       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning:\n",
    "df.dropna()\n",
    "df.fillna()\n",
    "df.clip()\n",
    "df.replace()\n",
    "df.drop_duplicates()\n",
    "df.drop_duplicates()\n",
    "df.fillna()\n",
    "df.merge()\n",
    "df.pivot()\n",
    "df.rename()\n",
    "df.query()\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df['column_name'].interpolate(inplace=True)\n",
    "os.listdir('data')\n",
    "\n",
    "Data Wrangling:\n",
    "df.melt()\n",
    "df.pivot()\n",
    "df.stack()\n",
    "df.unstack()\n",
    "df.astype()\n",
    "df.get()\n",
    "df.apply()\n",
    "pd.crosstab()\n",
    "pd.concat()\n",
    "df.rename()\n",
    "df.replace()\n",
    "df.sort_values()\n",
    "df.transform()\n",
    "\n",
    "Data Exploration:\n",
    "df.info()\n",
    "df.describe()\n",
    "df.value_counts()\n",
    "\n",
    "Data Visualization:\n",
    "plotly.plot()\n",
    "seaborn.plot()\n",
    "bokeh.plot()\n",
    "ggplot.plot()\n",
    "matplotlib.plot()\n",
    "plot.plot()\n",
    "holoviews.plot()\n",
    "\n",
    "Data Transformation:\n",
    "df.log()\n",
    "df.exp()\n",
    "df.normalize()\n",
    "df.scale()\n",
    "df.power()\n",
    "df.abs()\n",
    "df.rescale()\n",
    "df.subtract()\n",
    "df.divide()\n",
    "df.add()\n",
    "df.expit()\n",
    "df.cumsum()\n",
    "\n",
    "Feature Engineering:\n",
    "df.discretize()\n",
    "df.binarize()\n",
    "df.rank()\n",
    "df.dummies()\n",
    "df.group_enc()\n",
    "df.interactions()\n",
    "df.frequency()\n",
    "df.scaling/discretize()\n",
    "df.non-linear_trans()\n",
    "\n",
    "Time Series Analysis:\n",
    "df.pct()\n",
    "df.shift()\n",
    "df.diff()\n",
    "df.pct_change()\n",
    "df.autocorr()/df.pacf()\n",
    "df.rolling()\n",
    "df.forecast()\n",
    "df.rolling_window()\n",
    "\n",
    "Statistical Analysis:\n",
    "df.describe()\n",
    "df.skew()\n",
    "df.kurtosis()\n",
    "df.corr()\n",
    "stats.ttest_ind()\n",
    "statsmodels.stats.ztest()\n",
    "stats.chi2_contingency()\n",
    "stats.f_oneway()\n",
    "statsmodels.formula.api.ols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning:\n",
    "df.dropna()\n",
    "df.fillna()\n",
    "df.clip()\n",
    "df.replace()\n",
    "df.drop_duplicates()\n",
    "df.drop_duplicates()\n",
    "df.fillna()\n",
    "df.merge()\n",
    "df.pivot()\n",
    "df.rename()\n",
    "df.query()\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df['column_name'].interpolate(inplace=True)\n",
    "os.listdir('data')\n",
    "\n",
    "Data Wrangling:\n",
    "df.melt()\n",
    "df.pivot()\n",
    "df.stack()\n",
    "df.unstack()\n",
    "df.astype()\n",
    "df.get()\n",
    "df.apply()\n",
    "pd.crosstab()\n",
    "pd.concat()\n",
    "df.rename()\n",
    "df.replace()\n",
    "df.sort_values()\n",
    "df.transform()\n",
    "\n",
    "Data Exploration:\n",
    "df.info()\n",
    "df.describe()\n",
    "df.value_counts()\n",
    "\n",
    "Data Visualization:\n",
    "plotly.plot()\n",
    "seaborn.plot()\n",
    "bokeh.plot()\n",
    "ggplot.plot()\n",
    "matplotlib.plot()\n",
    "plot.plot()\n",
    "holoviews.plot()\n",
    "\n",
    "Data Transformation:\n",
    "df.log()\n",
    "df.exp()\n",
    "df.normalize()\n",
    "df.scale()\n",
    "df.power()\n",
    "df.abs()\n",
    "df.rescale()\n",
    "df.subtract()\n",
    "df.divide()\n",
    "df.add()\n",
    "df.expit()\n",
    "df.cumsum()\n",
    "\n",
    "Feature Engineering:\n",
    "df.discretize()\n",
    "df.binarize()\n",
    "df.rank()\n",
    "df.dummies()\n",
    "df.group_enc()\n",
    "df.interactions()\n",
    "df.frequency()\n",
    "df.scaling/discretize()\n",
    "df.non-linear_trans()\n",
    "\n",
    "Time Series Analysis:\n",
    "df.pct()\n",
    "df.shift()\n",
    "df.diff()\n",
    "df.pct_change()\n",
    "df.autocorr()/df.pacf()\n",
    "df.rolling()\n",
    "df.forecast()\n",
    "df.rolling_window()\n",
    "\n",
    "Statistical Analysis:\n",
    "df.describe()\n",
    "df.skew()\n",
    "df.kurtosis()\n",
    "df.corr()\n",
    "stats.ttest_ind()\n",
    "statsmodels.stats.ztest()\n",
    "stats.chi2_contingency()\n",
    "stats.f_oneway()\n",
    "statsmodels.formula.api.ols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions and techniques:\n",
    "Data Cleaning:\n",
    "df.dropna()\n",
    "df.fillna()\n",
    "df.clip()\n",
    "df.replace()\n",
    "df.drop_duplicates()\n",
    "df.drop_duplicates()\n",
    "df.fillna()\n",
    "df.merge()\n",
    "df.pivot()\n",
    "df.rename()\n",
    "df.query()\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df['column_name'].interpolate(inplace=True)\n",
    "os.listdir('data')\n",
    "Data Wrangling:\n",
    "df.melt()\n",
    "df.pivot()\n",
    "df.stack()\n",
    "df.unstack()\n",
    "df.astype()\n",
    "df.get()\n",
    "df.apply()\n",
    "pd.crosstab()\n",
    "pd.concat()\n",
    "df.rename()\n",
    "df.replace()\n",
    "df.sort_values()\n",
    "df.transform()\n",
    "Data Exploration:\n",
    "df.info()\n",
    "df.describe()\n",
    "df.value_counts()\n",
    "Data Visualization:\n",
    "plotly.plot()\n",
    "seaborn.plot()\n",
    "bokeh.plot()\n",
    "ggplot.plot()\n",
    "matplotlib.plot()\n",
    "plot.plot()\n",
    "holoviews.plot()\n",
    "Data Transformation:\n",
    "df.log()\n",
    "df.exp()\n",
    "df.normalize()\n",
    "df.scale()\n",
    "df.power()\n",
    "df.abs()\n",
    "df.rescale()\n",
    "df.subtract()\n",
    "df.divide()\n",
    "df.add()\n",
    "df.expit()\n",
    "df.cumsum()\n",
    "Feature Engineering:\n",
    "df.discretize()\n",
    "df.binarize()\n",
    "df.rank()\n",
    "df.dummies()\n",
    "df.group_enc()\n",
    "df.interactions()\n",
    "df.frequency()\n",
    "df.scaling/discretize()\n",
    "df.non-linear_trans()\n",
    "Time Series Analysis:\n",
    "df.pct()\n",
    "df.shift()\n",
    "df.diff()\n",
    "df.pct_change()\n",
    "df.autocorr()/df.pacf()\n",
    "df.rolling()\n",
    "df.forecast()\n",
    "df.rolling_window()\n",
    "Statistical Analysis:\n",
    "df.describe()\n",
    "df.skew()\n",
    "df.kurtosis()\n",
    "df.corr()\n",
    "stats.ttest_ind()\n",
    "statsmodels.stats.ztest()\n",
    "stats.chi2_contingency()\n",
    "stats.f_oneway()\n",
    "statsmodels.formula.api.ols()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"The os module in Python provides a way of interacting with the operating \n",
    "system. It provides various functions to work with file systems,\n",
    "directories, processes, and environment variables. Here are some \n",
    "of the commonly used functions in the os module#\n",
    "\"\"\"\n",
    "os.name\n",
    "os.getcwd()\n",
    "os.chdir(path)\n",
    "os.mkdir(path)\n",
    "os.makedirs(path)\n",
    "os.rmdir(path)\n",
    "os.removedirs(path)\n",
    "os.listdir(path)\n",
    "os.path.join(path, *paths)\n",
    "os.path.exists(path)\n",
    "os.path.isfile(path)\n",
    "os.path.isdir(path)\n",
    "os.path.basename(path)\n",
    "os.path.dirname(path)\n",
    "os.path.splitext(path)\n",
    "os.rename(src, dst)\n",
    "os.remove(path)\n",
    "os.system(command)\n",
    "os.name# Returns os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "1012.78px",
    "width": "507.775px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents (Clickable in sidebar)",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "1166.7px",
    "left": "1576px",
    "top": "1389.19px",
    "width": "497px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "890563eb1401dd7c5eac482b2070a231034cb0eabe59bf1a3eb86f9e36919f52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
