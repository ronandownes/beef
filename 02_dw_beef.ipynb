{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents (Clickable in sidebar)<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#The-revised-research-question\" data-toc-modified-id=\"The-revised-research-question-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>The revised research question</a></span></li><li><span><a href=\"#Libraries-and-modules\" data-toc-modified-id=\"Libraries-and-modules-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Libraries and modules</a></span></li><li><span><a href=\"#Combine-CCKP--Timeseries-Files-and-Add-a-CountryYear-Key\" data-toc-modified-id=\"Combine-CCKP--Timeseries-Files-and-Add-a-CountryYear-Key-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Combine CCKP  Timeseries Files and Add a CountryYear Key</a></span></li><li><span><a href=\"#The-Climate-Change-Knowledge-Portal.-(n.d.).-Retrieved-February-20,-2023,-from-https://climateknowledgeportal.worldbank.org/\" data-toc-modified-id=\"The-Climate-Change-Knowledge-Portal.-(n.d.).-Retrieved-February-20,-2023,-from-https://climateknowledgeportal.worldbank.org/-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>The Climate Change Knowledge Portal. (n.d.). Retrieved February 20, 2023, from <a href=\"https://climateknowledgeportal.worldbank.org/\" rel=\"nofollow\" target=\"_blank\">https://climateknowledgeportal.worldbank.org/</a></a></span></li><li><span><a href=\"#The-FAOSTAT-and-CCKP-data-become-one!\" data-toc-modified-id=\"The-FAOSTAT-and-CCKP-data-become-one!-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>The FAOSTAT and CCKP data become one!</a></span></li><li><span><a href=\"#Visualisation\" data-toc-modified-id=\"Visualisation-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Visualisation</a></span></li><li><span><a href=\"#Distribution-of-Beef-Stocks-Production-by-Country-and-Year\" data-toc-modified-id=\"Distribution-of-Beef-Stocks-Production-by-Country-and-Year-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Distribution of Beef Stocks Production by Country and Year</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Input/Output:\" data-toc-modified-id=\"Data-Input/Output:-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Data Input/Output:</a></span></li><li><span><a href=\"#Data-Cleaning:\" data-toc-modified-id=\"Data-Cleaning:-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Data Cleaning:</a></span></li><li><span><a href=\"#Data-Exploration:\" data-toc-modified-id=\"Data-Exploration:-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>Data Exploration:</a></span></li><li><span><a href=\"#Data-Transformation\" data-toc-modified-id=\"Data-Transformation-8.4\"><span class=\"toc-item-num\">8.4&nbsp;&nbsp;</span>Data Transformation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Split\" data-toc-modified-id=\"Split-8.4.1\"><span class=\"toc-item-num\">8.4.1&nbsp;&nbsp;</span>Split</a></span></li></ul></li><li><span><a href=\"#Data-Combination:\" data-toc-modified-id=\"Data-Combination:-8.5\"><span class=\"toc-item-num\">8.5&nbsp;&nbsp;</span>Data Combination:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pascal\" data-toc-modified-id=\"Pascal-8.5.1\"><span class=\"toc-item-num\">8.5.1&nbsp;&nbsp;</span>Pascal</a></span></li><li><span><a href=\"#Total-Character\" data-toc-modified-id=\"Total-Character-8.5.2\"><span class=\"toc-item-num\">8.5.2&nbsp;&nbsp;</span>Total Character</a></span></li></ul></li><li><span><a href=\"#Scanners,--Readers-and-Writers\" data-toc-modified-id=\"Scanners,--Readers-and-Writers-8.6\"><span class=\"toc-item-num\">8.6&nbsp;&nbsp;</span>Scanners,  Readers and Writers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scanners\" data-toc-modified-id=\"Scanners-8.6.1\"><span class=\"toc-item-num\">8.6.1&nbsp;&nbsp;</span>Scanners</a></span></li><li><span><a href=\"#Readers\" data-toc-modified-id=\"Readers-8.6.2\"><span class=\"toc-item-num\">8.6.2&nbsp;&nbsp;</span>Readers</a></span></li><li><span><a href=\"#Splitters\" data-toc-modified-id=\"Splitters-8.6.3\"><span class=\"toc-item-num\">8.6.3&nbsp;&nbsp;</span>Splitters</a></span></li><li><span><a href=\"#Delete\" data-toc-modified-id=\"Delete-8.6.4\"><span class=\"toc-item-num\">8.6.4&nbsp;&nbsp;</span>Delete</a></span></li><li><span><a href=\"#Rename\" data-toc-modified-id=\"Rename-8.6.5\"><span class=\"toc-item-num\">8.6.5&nbsp;&nbsp;</span>Rename</a></span></li><li><span><a href=\"#Replace\" data-toc-modified-id=\"Replace-8.6.6\"><span class=\"toc-item-num\">8.6.6&nbsp;&nbsp;</span>Replace</a></span></li></ul></li><li><span><a href=\"#Data-Processing\" data-toc-modified-id=\"Data-Processing-8.7\"><span class=\"toc-item-num\">8.7&nbsp;&nbsp;</span>Data Processing</a></span></li><li><span><a href=\"#String-Manipulation\" data-toc-modified-id=\"String-Manipulation-8.8\"><span class=\"toc-item-num\">8.8&nbsp;&nbsp;</span>String Manipulation</a></span></li><li><span><a href=\"#File-System-Operations\" data-toc-modified-id=\"File-System-Operations-8.9\"><span class=\"toc-item-num\">8.9&nbsp;&nbsp;</span>File System Operations</a></span></li></ul></li><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Modules-Functions-Libraries-and-How-to-Use\" data-toc-modified-id=\"Modules-Functions-Libraries-and-How-to-Use-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Modules Functions Libraries and How to Use</a></span></li><li><span><a href=\"#Appendices\" data-toc-modified-id=\"Appendices-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Appendices</a></span><ul class=\"toc-item\"><li><span><a href=\"#FAOSTAT-Data-Domains\" data-toc-modified-id=\"FAOSTAT-Data-Domains-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>FAOSTAT Data Domains</a></span></li></ul></li><li><span><a href=\"#Climate--Data-Preparation\" data-toc-modified-id=\"Climate--Data-Preparation-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Climate  Data Preparation</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#About-FAOSTAT\" data-toc-modified-id=\"About-FAOSTAT-12.0.1\"><span class=\"toc-item-num\">12.0.1&nbsp;&nbsp;</span>About FAOSTAT</a></span></li><li><span><a href=\"#Licencing\" data-toc-modified-id=\"Licencing-12.0.2\"><span class=\"toc-item-num\">12.0.2&nbsp;&nbsp;</span>Licencing</a></span></li><li><span><a href=\"#CCKP-Data--and-an-initial-bit-of-EDA\" data-toc-modified-id=\"CCKP-Data--and-an-initial-bit-of-EDA-12.0.3\"><span class=\"toc-item-num\">12.0.3&nbsp;&nbsp;</span>CCKP Data  and an initial bit of EDA</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation and multivariate time series analysis  for Irish Beef Monday\n",
    "\n",
    "## The revised research question\n",
    "How has Ireland's beef sector performed compared to the EU 27 countries since 2000, and can we forecast future prices using this historical data? Additionally, what can we learn from sentiment analysis of the beef industry during this time period? By focusing on data from 2000 onwards, we can better capture the current state of the beef industry and make more relevant predictions about future trends. At the end of 1999, the Benelux union ceased to report beef stock data as a single entity, as each member country began reporting its data individually. This change reflected the increasing economic development and growth of the individual countries within the union. This not only created the data reason for us to only researh the 21st era but it also provides a fiscal reason for the refining of the researh question.\n",
    "## Libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Data Manipulation and Analysis\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fancyimpute\n",
    "import missingno as msno\n",
    "from functools import partial, reduce\n",
    "\n",
    "### Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "### Statistical Analysis\n",
    "from scipy.stats import ks_2samp, shapiro\n",
    "\n",
    "### Machine Learning\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet, Lasso, LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "### Text Processing\n",
    "import html\n",
    "import re\n",
    "\n",
    "### Country Information\n",
    "from countryinfo import CountryInfo\n",
    "import pycountry\n",
    "from countrygroups import EUROPEAN_UNION\n",
    "\n",
    "### File System and OS\n",
    "import glob\n",
    "import os\n",
    "\n",
    "### Date and Time\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "### Data Presentation\n",
    "from tabulate import tabulate\n",
    "from IPython.display import HTML, Image, display\n",
    "\n",
    "### Data Types\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  Combine CCKP  Timeseries Files and Add a CountryYear Key\n",
    "\n",
    "The combine_timeseries_files function reads multiple CSV files from the rain or temperature subfolders.Referencing the first five rows of Rain_IRL_df  below  the first unnamed column gives the year and based on position the name of the country is extracted. The function then forms a Key by concatrenating the Country and Year values together. This 'Key' column  will be  used to merge with our Cattle Stocks data   to single dataframe. It filters to only include the first two columns, which are Year and corresponding weather measurements and as such, it drops all redundant regional readings. The resulting dataframe contains the weather data of 27 European countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Variable:</th>\n",
       "      <th>pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <th>Ireland</th>\n",
       "      <th>Carlow</th>\n",
       "      <th>Cavan</th>\n",
       "      <th>Clare</th>\n",
       "      <th>Cork</th>\n",
       "      <th>Donegal</th>\n",
       "      <th>Dublin</th>\n",
       "      <th>Galway</th>\n",
       "      <th>Kerry</th>\n",
       "      <th>Kildare</th>\n",
       "      <th>Kilkenny</th>\n",
       "      <th>Laois</th>\n",
       "      <th>Leitrim</th>\n",
       "      <th>Limerick</th>\n",
       "      <th>Longford</th>\n",
       "      <th>Louth</th>\n",
       "      <th>Mayo</th>\n",
       "      <th>Meath</th>\n",
       "      <th>Monaghan</th>\n",
       "      <th>Munster</th>\n",
       "      <th>Offaly</th>\n",
       "      <th>Roscommon</th>\n",
       "      <th>Sligo</th>\n",
       "      <th>Tipperary</th>\n",
       "      <th>Waterford</th>\n",
       "      <th>Westmeath</th>\n",
       "      <td>Wexford</td>\n",
       "      <td>Wicklow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901.0</th>\n",
       "      <th>1068.52</th>\n",
       "      <th>983.20</th>\n",
       "      <th>1018.93</th>\n",
       "      <th>1055.24</th>\n",
       "      <th>1153.06</th>\n",
       "      <th>1288.02</th>\n",
       "      <th>942.31</th>\n",
       "      <th>1044.95</th>\n",
       "      <th>1323.52</th>\n",
       "      <th>861.02</th>\n",
       "      <th>945.54</th>\n",
       "      <th>882.59</th>\n",
       "      <th>1184.19</th>\n",
       "      <th>1059.33</th>\n",
       "      <th>986.53</th>\n",
       "      <th>875.52</th>\n",
       "      <th>1156.31</th>\n",
       "      <th>861.07</th>\n",
       "      <th>933.47</th>\n",
       "      <th>933.47</th>\n",
       "      <th>851.14</th>\n",
       "      <th>1008.41</th>\n",
       "      <th>1206.83</th>\n",
       "      <th>1030.92</th>\n",
       "      <th>1129.96</th>\n",
       "      <th>901.61</th>\n",
       "      <td>988.85</td>\n",
       "      <td>978.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902.0</th>\n",
       "      <th>1016.31</th>\n",
       "      <th>965.42</th>\n",
       "      <th>939.44</th>\n",
       "      <th>1004.48</th>\n",
       "      <th>1119.44</th>\n",
       "      <th>1167.77</th>\n",
       "      <th>934.83</th>\n",
       "      <th>984.17</th>\n",
       "      <th>1277.05</th>\n",
       "      <th>857.92</th>\n",
       "      <th>926.28</th>\n",
       "      <th>863.97</th>\n",
       "      <th>1076.99</th>\n",
       "      <th>1022.06</th>\n",
       "      <th>907.86</th>\n",
       "      <th>834.92</th>\n",
       "      <th>1053.70</th>\n",
       "      <th>824.53</th>\n",
       "      <th>864.39</th>\n",
       "      <th>864.39</th>\n",
       "      <th>831.83</th>\n",
       "      <th>943.86</th>\n",
       "      <th>1087.75</th>\n",
       "      <th>1002.13</th>\n",
       "      <th>1101.99</th>\n",
       "      <th>852.81</th>\n",
       "      <td>967.98</td>\n",
       "      <td>966.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903.0</th>\n",
       "      <th>1368.16</th>\n",
       "      <th>1282.10</th>\n",
       "      <th>1235.62</th>\n",
       "      <th>1376.31</th>\n",
       "      <th>1525.32</th>\n",
       "      <th>1564.40</th>\n",
       "      <th>1197.84</th>\n",
       "      <th>1350.96</th>\n",
       "      <th>1747.10</th>\n",
       "      <th>1101.33</th>\n",
       "      <th>1236.78</th>\n",
       "      <th>1156.36</th>\n",
       "      <th>1443.61</th>\n",
       "      <th>1392.88</th>\n",
       "      <th>1209.04</th>\n",
       "      <th>1055.55</th>\n",
       "      <th>1445.43</th>\n",
       "      <th>1055.06</th>\n",
       "      <th>1131.68</th>\n",
       "      <th>1131.68</th>\n",
       "      <th>1116.15</th>\n",
       "      <th>1280.60</th>\n",
       "      <th>1479.39</th>\n",
       "      <th>1355.40</th>\n",
       "      <th>1484.59</th>\n",
       "      <th>1134.94</th>\n",
       "      <td>1275.17</td>\n",
       "      <td>1256.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904.0</th>\n",
       "      <th>1081.95</th>\n",
       "      <th>970.03</th>\n",
       "      <th>985.97</th>\n",
       "      <th>1114.46</th>\n",
       "      <th>1235.12</th>\n",
       "      <th>1282.28</th>\n",
       "      <th>902.41</th>\n",
       "      <th>1069.77</th>\n",
       "      <th>1421.42</th>\n",
       "      <th>844.14</th>\n",
       "      <th>938.61</th>\n",
       "      <th>872.85</th>\n",
       "      <th>1151.71</th>\n",
       "      <th>1107.92</th>\n",
       "      <th>946.22</th>\n",
       "      <th>824.66</th>\n",
       "      <th>1164.06</th>\n",
       "      <th>826.20</th>\n",
       "      <th>906.37</th>\n",
       "      <th>906.37</th>\n",
       "      <th>840.18</th>\n",
       "      <th>1003.16</th>\n",
       "      <th>1173.82</th>\n",
       "      <th>1041.08</th>\n",
       "      <th>1144.26</th>\n",
       "      <th>873.39</th>\n",
       "      <td>974.31</td>\n",
       "      <td>950.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                   Variable:  \\\n",
       "NaN    Ireland Carlow  Cavan   Clare   Cork    Donegal Dublin  Galway  Kerry   Kildare Kilkenny Laois   Leitrim Limerick Longford Louth   Mayo    Meath   Monaghan Munster Offaly  Roscommon Sligo   Tipperary Waterford Westmeath   Wexford   \n",
       "1901.0 1068.52 983.20  1018.93 1055.24 1153.06 1288.02 942.31  1044.95 1323.52 861.02  945.54   882.59  1184.19 1059.33  986.53   875.52  1156.31 861.07  933.47   933.47  851.14  1008.41   1206.83 1030.92   1129.96   901.61       988.85   \n",
       "1902.0 1016.31 965.42  939.44  1004.48 1119.44 1167.77 934.83  984.17  1277.05 857.92  926.28   863.97  1076.99 1022.06  907.86   834.92  1053.70 824.53  864.39   864.39  831.83  943.86    1087.75 1002.13   1101.99   852.81       967.98   \n",
       "1903.0 1368.16 1282.10 1235.62 1376.31 1525.32 1564.40 1197.84 1350.96 1747.10 1101.33 1236.78  1156.36 1443.61 1392.88  1209.04  1055.55 1445.43 1055.06 1131.68  1131.68 1116.15 1280.60   1479.39 1355.40   1484.59   1134.94     1275.17   \n",
       "1904.0 1081.95 970.03  985.97  1114.46 1235.12 1282.28 902.41  1069.77 1421.42 844.14  938.61   872.85  1151.71 1107.92  946.22   824.66  1164.06 826.20  906.37   906.37  840.18  1003.16   1173.82 1041.08   1144.26   873.39       974.31   \n",
       "\n",
       "                                                                                                                                                                                                                                         pr  \n",
       "NaN    Ireland Carlow  Cavan   Clare   Cork    Donegal Dublin  Galway  Kerry   Kildare Kilkenny Laois   Leitrim Limerick Longford Louth   Mayo    Meath   Monaghan Munster Offaly  Roscommon Sligo   Tipperary Waterford Westmeath  Wicklow  \n",
       "1901.0 1068.52 983.20  1018.93 1055.24 1153.06 1288.02 942.31  1044.95 1323.52 861.02  945.54   882.59  1184.19 1059.33  986.53   875.52  1156.31 861.07  933.47   933.47  851.14  1008.41   1206.83 1030.92   1129.96   901.61      978.16  \n",
       "1902.0 1016.31 965.42  939.44  1004.48 1119.44 1167.77 934.83  984.17  1277.05 857.92  926.28   863.97  1076.99 1022.06  907.86   834.92  1053.70 824.53  864.39   864.39  831.83  943.86    1087.75 1002.13   1101.99   852.81      966.45  \n",
       "1903.0 1368.16 1282.10 1235.62 1376.31 1525.32 1564.40 1197.84 1350.96 1747.10 1101.33 1236.78  1156.36 1443.61 1392.88  1209.04  1055.55 1445.43 1055.06 1131.68  1131.68 1116.15 1280.60   1479.39 1355.40   1484.59   1134.94    1256.88  \n",
       "1904.0 1081.95 970.03  985.97  1114.46 1235.12 1282.28 902.41  1069.77 1421.42 844.14  938.61   872.85  1151.71 1107.92  946.22   824.66  1164.06 826.20  906.37   906.37  840.18  1003.16   1173.82 1041.08   1144.26   873.39      950.28  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rain_IRL_df = pd.read_csv('rain/pr_timeseries_annual_cru_1901-2021_IRL.csv')# loads the individual Irish rain data\n",
    "Rain_IRL_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## The Climate Change Knowledge Portal. (n.d.). Retrieved February 20, 2023, from https://climateknowledgeportal.worldbank.org/\n",
    "\n",
    "The Climate Change Knowledge Portal. (n.d.). Retrieved February 20, 2023, from https://climateknowledgeportal.worldbank.org/\n",
    "\n",
    "| Rainfall data files from 'rain folder  | Temperature data files from 'tempature folder|\n",
    "|:----------:|:----------------:|\n",
    "| pr_timeseries_annual_cru_1901-2021_AUT.csv | tas_timeseries_annual_cru_1901-2021_AUT.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_BEL.csv | tas_timeseries_annual_cru_1901-2021_BEL.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_BGR.csv | tas_timeseries_annual_cru_1901-2021_BGR.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_CYP.csv | tas_timeseries_annual_cru_1901-2021_CYP.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_CZE.csv | tas_timeseries_annual_cru_1901-2021_CZE.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_DEU.csv | tas_timeseries_annual_cru_1901-2021_DEU.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_DNK.csv | tas_timeseries_annual_cru_1901-2021_DNK.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_ESP.csv | tas_timeseries_annual_cru_1901-2021_ESP.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_EST.csv | tas_timeseries_annual_cru_1901-2021_EST.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_FIN.csv | tas_timeseries_annual_cru_1901-2021_FIN.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_FRA.csv | tas_timeseries_annual_cru_1901-2021_FRA.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_GRC.csv | tas_timeseries_annual_cru_1901-2021_GRC.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_HRV.csv | tas_timeseries_annual_cru_1901-2021_HRV.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_HUN.csv | tas_timeseries_annual_cru_1901-2021_HUN.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_IRL.csv | tas_timeseries_annual_cru_1901-2021_IRL.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_ITA.csv | tas_timeseries_annual_cru_1901-2021_ITA.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_LTU.csv | tas_timeseries_annual_cru_1901-2021_LTU.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_LUX.csv | tas_timeseries_annual_cru_1901-2021_LUX.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_LVA.csv | tas_timeseries_annual_cru_1901-2021_LVA.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_MLT.csv | tas_timeseries_annual_cru_1901-2021_MLT.csv |\n",
    "| pr_timeseries_annual_cru_1901-2021_NLD.csv | tas_timeseries_annual_cru_1901-202\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_timeseries_files(path: str, subfolder: str, col_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Reads in all CSV files in the given subfolder of the directory, renames the first unnamed column based on its position,\n",
    "    and combines the resulting dataframes together into a single dataframe.\n",
    "    Args:\n",
    "        path (str): The relative path of the directory containing the data.\n",
    "        subfolder (str): The name of the subfolder within the directory to read the CSV files from.\n",
    "        col_name (str): The name to assign to the specified column in the resulting dataframe.\n",
    "    Returns:\n",
    "        pandas.DataFrame: The resulting dataframe after combining data from all CSV files in the specified subfolder.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        folder_path = os.path.join(path, subfolder)\n",
    "        csv_filenames = glob.glob(folder_path + \"/*.csv\")\n",
    "        # Read in all CSV files, rename the first unnamed column based on position, and filter to only include the 'key' and specified column\n",
    "        processed_dfs = []\n",
    "        for filename in csv_filenames:\n",
    "            file_path = os.path.join(path, subfolder, os.path.basename(filename))\n",
    "            df = pd.read_csv(file_path, on_bad_lines='skip', skiprows=1)\n",
    "            if df.columns[0].startswith(\"Unnamed\"):\n",
    "                df.rename(columns={df.columns[0]: \"Year\"}, inplace=True)\n",
    "            df['Key'] = df.columns[1] + df['Year'].astype(str)\n",
    "            df.rename(columns={df.columns[1]: col_name}, inplace=True)\n",
    "            df = df.filter(['Key', col_name])\n",
    "            processed_dfs.append(df)\n",
    "        # Concatenate all dataframes into a single dataframe\n",
    "        df = pd.concat(processed_dfs, ignore_index=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error combining CSV files in folder {folder_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The FAOSTAT and CCKP data become one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>R_mm/y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria1901</td>\n",
       "      <td>1052.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria1902</td>\n",
       "      <td>1061.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria1903</td>\n",
       "      <td>1201.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria1904</td>\n",
       "      <td>1146.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria1905</td>\n",
       "      <td>1127.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Key   R_mm/y\n",
       "0  Austria1901  1052.84\n",
       "1  Austria1902  1061.55\n",
       "2  Austria1903  1201.34\n",
       "3  Austria1904  1146.14\n",
       "4  Austria1905  1127.85"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rain_df = combine_timeseries_files('', 'rain', 'R_mm/y')\n",
    "# save the rain DataFrame to a CSV file\n",
    "rain_df.to_csv('clean/rain.csv', index=False)\n",
    "rain_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>T(°C)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria1901</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria1902</td>\n",
       "      <td>5.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria1903</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria1904</td>\n",
       "      <td>6.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria1905</td>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>Sweden2017</td>\n",
       "      <td>3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>Sweden2018</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>Sweden2019</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>Sweden2020</td>\n",
       "      <td>4.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>Sweden2021</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3267 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Key  T(°C)\n",
       "0     Austria1901   5.41\n",
       "1     Austria1902   5.34\n",
       "2     Austria1903   5.88\n",
       "3     Austria1904   6.22\n",
       "4     Austria1905   5.79\n",
       "...           ...    ...\n",
       "3262   Sweden2017   3.16\n",
       "3263   Sweden2018   3.62\n",
       "3264   Sweden2019   3.34\n",
       "3265   Sweden2020   4.47\n",
       "3266   Sweden2021   3.02\n",
       "\n",
       "[3267 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df = combine_timeseries_files('', 'temperature', 'T(\\u00b0C)')\n",
    "# save the rain DataFrame to a CSV file\n",
    "temperature_df.to_csv('clean/temperature.csv', index=False)\n",
    "temperature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2000</td>\n",
       "      <td>2152811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2001</td>\n",
       "      <td>2155447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2002</td>\n",
       "      <td>2118454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2003</td>\n",
       "      <td>2066942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2004</td>\n",
       "      <td>2052033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2017</td>\n",
       "      <td>1448590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2018</td>\n",
       "      <td>1435450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2019</td>\n",
       "      <td>1404670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2020</td>\n",
       "      <td>1390960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2021</td>\n",
       "      <td>1389890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Year    Stock\n",
       "0    Austria  2000  2152811\n",
       "1    Austria  2001  2155447\n",
       "2    Austria  2002  2118454\n",
       "3    Austria  2003  2066942\n",
       "4    Austria  2004  2052033\n",
       "..       ...   ...      ...\n",
       "589   Sweden  2017  1448590\n",
       "590   Sweden  2018  1435450\n",
       "591   Sweden  2019  1404670\n",
       "592   Sweden  2020  1390960\n",
       "593   Sweden  2021  1389890\n",
       "\n",
       "[594 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stock_df = pd.read_csv('clean/stock.csv')# loads the cleaned cattle stock  CSV file to pandas DataFrame n df\n",
    "\n",
    "df=stock_df\n",
    "stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2000</td>\n",
       "      <td>2152811</td>\n",
       "      <td>Austria2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2001</td>\n",
       "      <td>2155447</td>\n",
       "      <td>Austria2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2002</td>\n",
       "      <td>2118454</td>\n",
       "      <td>Austria2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2003</td>\n",
       "      <td>2066942</td>\n",
       "      <td>Austria2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2004</td>\n",
       "      <td>2052033</td>\n",
       "      <td>Austria2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2017</td>\n",
       "      <td>1448590</td>\n",
       "      <td>Sweden2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2018</td>\n",
       "      <td>1435450</td>\n",
       "      <td>Sweden2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2019</td>\n",
       "      <td>1404670</td>\n",
       "      <td>Sweden2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2020</td>\n",
       "      <td>1390960</td>\n",
       "      <td>Sweden2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2021</td>\n",
       "      <td>1389890</td>\n",
       "      <td>Sweden2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Year    Stock          Key\n",
       "0    Austria  2000  2152811  Austria2000\n",
       "1    Austria  2001  2155447  Austria2001\n",
       "2    Austria  2002  2118454  Austria2002\n",
       "3    Austria  2003  2066942  Austria2003\n",
       "4    Austria  2004  2052033  Austria2004\n",
       "..       ...   ...      ...          ...\n",
       "589   Sweden  2017  1448590   Sweden2017\n",
       "590   Sweden  2018  1435450   Sweden2018\n",
       "591   Sweden  2019  1404670   Sweden2019\n",
       "592   Sweden  2020  1390960   Sweden2020\n",
       "593   Sweden  2021  1389890   Sweden2021\n",
       "\n",
       "[594 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Key'] = df['Country'] + df['Year'].astype(str)# adds a unique key column \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Key</th>\n",
       "      <th>R_mm/y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2000</td>\n",
       "      <td>2152811</td>\n",
       "      <td>Austria2000</td>\n",
       "      <td>1171.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2001</td>\n",
       "      <td>2155447</td>\n",
       "      <td>Austria2001</td>\n",
       "      <td>1058.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2002</td>\n",
       "      <td>2118454</td>\n",
       "      <td>Austria2002</td>\n",
       "      <td>1212.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2003</td>\n",
       "      <td>2066942</td>\n",
       "      <td>Austria2003</td>\n",
       "      <td>891.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2004</td>\n",
       "      <td>2052033</td>\n",
       "      <td>Austria2004</td>\n",
       "      <td>1080.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2017</td>\n",
       "      <td>1448590</td>\n",
       "      <td>Sweden2017</td>\n",
       "      <td>678.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2018</td>\n",
       "      <td>1435450</td>\n",
       "      <td>Sweden2018</td>\n",
       "      <td>539.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2019</td>\n",
       "      <td>1404670</td>\n",
       "      <td>Sweden2019</td>\n",
       "      <td>682.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2020</td>\n",
       "      <td>1390960</td>\n",
       "      <td>Sweden2020</td>\n",
       "      <td>669.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2021</td>\n",
       "      <td>1389890</td>\n",
       "      <td>Sweden2021</td>\n",
       "      <td>608.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Year    Stock          Key   R_mm/y\n",
       "0    Austria  2000  2152811  Austria2000  1171.79\n",
       "1    Austria  2001  2155447  Austria2001  1058.36\n",
       "2    Austria  2002  2118454  Austria2002  1212.56\n",
       "3    Austria  2003  2066942  Austria2003   891.80\n",
       "4    Austria  2004  2052033  Austria2004  1080.30\n",
       "..       ...   ...      ...          ...      ...\n",
       "589   Sweden  2017  1448590   Sweden2017   678.22\n",
       "590   Sweden  2018  1435450   Sweden2018   539.63\n",
       "591   Sweden  2019  1404670   Sweden2019   682.36\n",
       "592   Sweden  2020  1390960   Sweden2020   669.34\n",
       "593   Sweden  2021  1389890   Sweden2021   608.87\n",
       "\n",
       "[594 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, rain_df, on='Key')\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Key</th>\n",
       "      <th>R_mm/y</th>\n",
       "      <th>T(°C)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2000</td>\n",
       "      <td>2152811</td>\n",
       "      <td>Austria2000</td>\n",
       "      <td>1171.79</td>\n",
       "      <td>7.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2001</td>\n",
       "      <td>2155447</td>\n",
       "      <td>Austria2001</td>\n",
       "      <td>1058.36</td>\n",
       "      <td>7.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2002</td>\n",
       "      <td>2118454</td>\n",
       "      <td>Austria2002</td>\n",
       "      <td>1212.56</td>\n",
       "      <td>7.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2003</td>\n",
       "      <td>2066942</td>\n",
       "      <td>Austria2003</td>\n",
       "      <td>891.80</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Austria</td>\n",
       "      <td>2004</td>\n",
       "      <td>2052033</td>\n",
       "      <td>Austria2004</td>\n",
       "      <td>1080.30</td>\n",
       "      <td>6.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2017</td>\n",
       "      <td>1448590</td>\n",
       "      <td>Sweden2017</td>\n",
       "      <td>678.22</td>\n",
       "      <td>3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2018</td>\n",
       "      <td>1435450</td>\n",
       "      <td>Sweden2018</td>\n",
       "      <td>539.63</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2019</td>\n",
       "      <td>1404670</td>\n",
       "      <td>Sweden2019</td>\n",
       "      <td>682.36</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2020</td>\n",
       "      <td>1390960</td>\n",
       "      <td>Sweden2020</td>\n",
       "      <td>669.34</td>\n",
       "      <td>4.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>2021</td>\n",
       "      <td>1389890</td>\n",
       "      <td>Sweden2021</td>\n",
       "      <td>608.87</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Year    Stock          Key   R_mm/y  T(°C)\n",
       "0    Austria  2000  2152811  Austria2000  1171.79   7.97\n",
       "1    Austria  2001  2155447  Austria2001  1058.36   7.03\n",
       "2    Austria  2002  2118454  Austria2002  1212.56   7.73\n",
       "3    Austria  2003  2066942  Austria2003   891.80   7.35\n",
       "4    Austria  2004  2052033  Austria2004  1080.30   6.75\n",
       "..       ...   ...      ...          ...      ...    ...\n",
       "589   Sweden  2017  1448590   Sweden2017   678.22   3.16\n",
       "590   Sweden  2018  1435450   Sweden2018   539.63   3.62\n",
       "591   Sweden  2019  1404670   Sweden2019   682.36   3.34\n",
       "592   Sweden  2020  1390960   Sweden2020   669.34   4.47\n",
       "593   Sweden  2021  1389890   Sweden2021   608.87   3.02\n",
       "\n",
       "[594 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, temperature_df, on='Key')\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arch\n",
      "cattle_meat_import_export.csv\n",
      "Fertilizer.csv\n",
      "Fertilizers.csv\n",
      "fertilizer].csv\n",
      "grasslands.csv\n",
      "land_pasture.csv\n",
      "land_use_all_items_area_eu28.csv\n",
      "manure.csv\n",
      "meat.csv\n",
      "nutrient.csv\n",
      "nutrients.csv\n",
      "price.csv\n",
      "pr_timeseries__IRL.csv\n",
      "stocks.csv\n",
      "tas_timeseries_IRL.csv\n",
      "temperature_change.csv\n",
      "temperature_sd.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dir_path = 'raw'\n",
    "for filename in os.listdir(dir_path):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain Code</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Area Code (M49)</th>\n",
       "      <th>Area</th>\n",
       "      <th>Element Code</th>\n",
       "      <th>Element</th>\n",
       "      <th>Item Code</th>\n",
       "      <th>Item</th>\n",
       "      <th>Year Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Value</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Flag Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RL</td>\n",
       "      <td>Land Use</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5110</td>\n",
       "      <td>Area</td>\n",
       "      <td>6600</td>\n",
       "      <td>Country area</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>1000 ha</td>\n",
       "      <td>8387.9</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RL</td>\n",
       "      <td>Land Use</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5110</td>\n",
       "      <td>Area</td>\n",
       "      <td>6600</td>\n",
       "      <td>Country area</td>\n",
       "      <td>1962</td>\n",
       "      <td>1962</td>\n",
       "      <td>1000 ha</td>\n",
       "      <td>8387.9</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RL</td>\n",
       "      <td>Land Use</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5110</td>\n",
       "      <td>Area</td>\n",
       "      <td>6600</td>\n",
       "      <td>Country area</td>\n",
       "      <td>1963</td>\n",
       "      <td>1963</td>\n",
       "      <td>1000 ha</td>\n",
       "      <td>8387.9</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RL</td>\n",
       "      <td>Land Use</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5110</td>\n",
       "      <td>Area</td>\n",
       "      <td>6600</td>\n",
       "      <td>Country area</td>\n",
       "      <td>1964</td>\n",
       "      <td>1964</td>\n",
       "      <td>1000 ha</td>\n",
       "      <td>8387.9</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RL</td>\n",
       "      <td>Land Use</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5110</td>\n",
       "      <td>Area</td>\n",
       "      <td>6600</td>\n",
       "      <td>Country area</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>1000 ha</td>\n",
       "      <td>8387.9</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Domain Code    Domain  Area Code (M49)     Area  Element Code Element  \\\n",
       "0          RL  Land Use               40  Austria          5110    Area   \n",
       "1          RL  Land Use               40  Austria          5110    Area   \n",
       "2          RL  Land Use               40  Austria          5110    Area   \n",
       "3          RL  Land Use               40  Austria          5110    Area   \n",
       "4          RL  Land Use               40  Austria          5110    Area   \n",
       "\n",
       "   Item Code          Item  Year Code  Year     Unit   Value Flag  \\\n",
       "0       6600  Country area       1961  1961  1000 ha  8387.9    A   \n",
       "1       6600  Country area       1962  1962  1000 ha  8387.9    A   \n",
       "2       6600  Country area       1963  1963  1000 ha  8387.9    A   \n",
       "3       6600  Country area       1964  1964  1000 ha  8387.9    A   \n",
       "4       6600  Country area       1965  1965  1000 ha  8387.9    A   \n",
       "\n",
       "  Flag Description  \n",
       "0  Official figure  \n",
       "1  Official figure  \n",
       "2  Official figure  \n",
       "3  Official figure  \n",
       "4  Official figure  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "land_df = pd.read_csv( 'raw/land.csv', on_bad_lines='skip')   # loads Land USe Domain\n",
    "land_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain Code            1\n",
      "Domain                 1\n",
      "Area Code (M49)       28\n",
      "Area                  28\n",
      "Element Code           1\n",
      "Element                1\n",
      "Item Code              6\n",
      "Item                   6\n",
      "Year Code             60\n",
      "Year                  60\n",
      "Unit                   1\n",
      "Value               2930\n",
      "Flag                   4\n",
      "Flag Description       4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_counts = land_df.nunique()\n",
    "print(unique_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Country area', 'Land area', 'Agriculture', 'Agricultural land',\n",
       "       'Land under temp. meadows and pastures',\n",
       "       'Land under perm. meadows and pastures'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_items = land_df['Item'].unique()\n",
    "unique_items \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows with 'land under temp. meadows and pastures'\n",
    "LandTemp_df = land_df.loc[land_df['Item'] == 'Land under temp. meadows and pastures']\n",
    "land_df.loc[land_df['Item'] == 'Land under temp. meadows and pastures', 'Key'] = land_df['Area'] + land_df['Year'].astype(str)\n",
    "LandTemp_df = LandTemp_df[LandTemp_df['Year'] >= 2000]\n",
    "LandTemp_df = LandTemp_df.rename(columns={'Value': 'LA_kh'})\n",
    "LandTemp_df = LandTemp_df.loc[:, ['LA_kh', 'Key']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain Code</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Area Code (M49)</th>\n",
       "      <th>Area</th>\n",
       "      <th>Element Code</th>\n",
       "      <th>Element</th>\n",
       "      <th>Item Code</th>\n",
       "      <th>Item</th>\n",
       "      <th>Year Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Value</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Flag Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>RL</td>\n",
       "      <td>Land Use</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5110</td>\n",
       "      <td>Area</td>\n",
       "      <td>6633</td>\n",
       "      <td>Land under temp. meadows and pastures</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>RL</td>\n",
       "      <td>Land Use</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5110</td>\n",
       "      <td>Area</td>\n",
       "      <td>6633</td>\n",
       "      <td>Land under temp. meadows and pastures</td>\n",
       "      <td>1962</td>\n",
       "      <td>1962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>RL</td>\n",
       "      <td>Land Use</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5110</td>\n",
       "      <td>Area</td>\n",
       "      <td>6633</td>\n",
       "      <td>Land under temp. meadows and pastures</td>\n",
       "      <td>1963</td>\n",
       "      <td>1963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>RL</td>\n",
       "      <td>Land Use</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5110</td>\n",
       "      <td>Area</td>\n",
       "      <td>6633</td>\n",
       "      <td>Land under temp. meadows and pastures</td>\n",
       "      <td>1964</td>\n",
       "      <td>1964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>RL</td>\n",
       "      <td>Land Use</td>\n",
       "      <td>40</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5110</td>\n",
       "      <td>Area</td>\n",
       "      <td>6633</td>\n",
       "      <td>Land under temp. meadows and pastures</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73375</th>\n",
       "      <td>RL</td>\n",
       "      <td>Land Use</td>\n",
       "      <td>752</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>5110</td>\n",
       "      <td>Area</td>\n",
       "      <td>6633</td>\n",
       "      <td>Land under temp. meadows and pastures</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>1000 ha</td>\n",
       "      <td>1052.56</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73376</th>\n",
       "      <td>RL</td>\n",
       "      <td>Land Use</td>\n",
       "      <td>752</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>5110</td>\n",
       "      <td>Area</td>\n",
       "      <td>6633</td>\n",
       "      <td>Land under temp. meadows and pastures</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1000 ha</td>\n",
       "      <td>1035.11</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73377</th>\n",
       "      <td>RL</td>\n",
       "      <td>Land Use</td>\n",
       "      <td>752</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>5110</td>\n",
       "      <td>Area</td>\n",
       "      <td>6633</td>\n",
       "      <td>Land under temp. meadows and pastures</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>1000 ha</td>\n",
       "      <td>1048.39</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73378</th>\n",
       "      <td>RL</td>\n",
       "      <td>Land Use</td>\n",
       "      <td>752</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>5110</td>\n",
       "      <td>Area</td>\n",
       "      <td>6633</td>\n",
       "      <td>Land under temp. meadows and pastures</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>1000 ha</td>\n",
       "      <td>1084.50</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73379</th>\n",
       "      <td>RL</td>\n",
       "      <td>Land Use</td>\n",
       "      <td>752</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>5110</td>\n",
       "      <td>Area</td>\n",
       "      <td>6633</td>\n",
       "      <td>Land under temp. meadows and pastures</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>1000 ha</td>\n",
       "      <td>1064.81</td>\n",
       "      <td>A</td>\n",
       "      <td>Official figure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1680 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Domain Code    Domain  Area Code (M49)     Area  Element Code Element  \\\n",
       "420            RL  Land Use               40  Austria          5110    Area   \n",
       "421            RL  Land Use               40  Austria          5110    Area   \n",
       "422            RL  Land Use               40  Austria          5110    Area   \n",
       "423            RL  Land Use               40  Austria          5110    Area   \n",
       "424            RL  Land Use               40  Austria          5110    Area   \n",
       "...           ...       ...              ...      ...           ...     ...   \n",
       "73375          RL  Land Use              752   Sweden          5110    Area   \n",
       "73376          RL  Land Use              752   Sweden          5110    Area   \n",
       "73377          RL  Land Use              752   Sweden          5110    Area   \n",
       "73378          RL  Land Use              752   Sweden          5110    Area   \n",
       "73379          RL  Land Use              752   Sweden          5110    Area   \n",
       "\n",
       "       Item Code                                   Item  Year Code  Year  \\\n",
       "420         6633  Land under temp. meadows and pastures       1961  1961   \n",
       "421         6633  Land under temp. meadows and pastures       1962  1962   \n",
       "422         6633  Land under temp. meadows and pastures       1963  1963   \n",
       "423         6633  Land under temp. meadows and pastures       1964  1964   \n",
       "424         6633  Land under temp. meadows and pastures       1965  1965   \n",
       "...          ...                                    ...        ...   ...   \n",
       "73375       6633  Land under temp. meadows and pastures       2016  2016   \n",
       "73376       6633  Land under temp. meadows and pastures       2017  2017   \n",
       "73377       6633  Land under temp. meadows and pastures       2018  2018   \n",
       "73378       6633  Land under temp. meadows and pastures       2019  2019   \n",
       "73379       6633  Land under temp. meadows and pastures       2020  2020   \n",
       "\n",
       "          Unit    Value Flag Flag Description  \n",
       "420        NaN      NaN  NaN              NaN  \n",
       "421        NaN      NaN  NaN              NaN  \n",
       "422        NaN      NaN  NaN              NaN  \n",
       "423        NaN      NaN  NaN              NaN  \n",
       "424        NaN      NaN  NaN              NaN  \n",
       "...        ...      ...  ...              ...  \n",
       "73375  1000 ha  1052.56    A  Official figure  \n",
       "73376  1000 ha  1035.11    A  Official figure  \n",
       "73377  1000 ha  1048.39    A  Official figure  \n",
       "73378  1000 ha  1084.50    A  Official figure  \n",
       "73379  1000 ha  1064.81    A  Official figure  \n",
       "\n",
       "[1680 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LandTemp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows with 'land under temp. meadows and pastures'\n",
    "lutpm_df = land_df.loc[land_df['Item'] == 'Land under temp. meadows and pastures']\n",
    "\n",
    "# Select header row and append to filtered data\n",
    "header_row = land_df.loc[land_df['Item'] == 'Item']\n",
    "lutpm_df = header_row.append(lutpm_df)\n",
    "\n",
    "unique_counts = lutpm_df.nunique()\n",
    "print(unique_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def filter_and_merge(named_df):\n",
    "    # Filter rows with year >= 2000\n",
    "    filtered_df = named_df.loc[named_df['Year'] >= 2000]\n",
    "\n",
    "    # Create new label as merge of 'Area' and 'Year' labels\n",
    "    filtered_df['Key'] = filtered_df['Area'] + filtered_df['Year'].astype(str)\n",
    "\n",
    "    return named_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddf=filter_and_merge(lutpm_df)\n",
    "ddf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lutpm_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir('.')) #List current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe for the temp data\n",
    "temp_df = combine('temperature', 'temperature  {temp_c}\\u00b0C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_c = 20\n",
    "print(f\"The temperature is {temp_c}\\u00b0C.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_df=combine('rain', 'Temperature_C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by country and select the column of interest\n",
    "grouped = df.groupby('Country')['Stocks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austria_df = grouped.get_group('Austria')\n",
    "austria_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_producers = df.groupby('Country')['Stocks'].sum().sort_values(ascending=False).head(5)\n",
    "print(top_producers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_grouped = df.groupby('Country')['Stocks'].sum().reset_index()\n",
    "df_grouped = df_grouped.sort_values(by='Stocks', ascending=False).reset_index(drop=True)\n",
    "plt.bar(df_grouped['Country'][:5], df_grouped['Stocks'][:5])\n",
    "plt.title('Top 5 Beef Producing Countries in European Union (EU) ' )\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Total Stocks')\n",
    "\n",
    "plt.xticks(rotation=90)  # rotate the x-axis labels by 90 degrees\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_grouped = df.groupby('Country')['Stocks'].sum().reset_index()\n",
    "df_grouped = df_grouped.sort_values(by='Stocks', ascending=False).reset_index(drop=True)\n",
    "plt.bar(df_grouped['Country'][:10], df_grouped['Stocks'][:10])\n",
    "plt.title('Top 10 Beef Producing Countries in European Union (EU) ')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Total Stocks')\n",
    "\n",
    "plt.xticks(rotation=90)  # rotate the x-axis labels by 90 degrees\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_grouped = df.groupby('Country')['Stocks'].sum().reset_index()\n",
    "df_grouped = df_grouped.sort_values(by='Stocks', ascending=False).reset_index(drop=True)\n",
    "\n",
    "plt.bar(df_grouped['Country'][:len(df_grouped)], df_grouped['Stocks'][:len(df_grouped)])\n",
    "\n",
    "plt.title('Distribution of Beef  Stocks  in European Union (EU) ')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Total Stocks')\n",
    "\n",
    "plt.xticks(rotation=90)  # rotate the x-axis labels by 90 degrees\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_heatmap = df.pivot_table(index='Country', columns='Year', values='Stocks')\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df_heatmap, cmap='YlOrRd', annot=True, fmt='g')\n",
    "plt.title('Distribution of Beef Stocks Production by Country and Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Country')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Beef Stocks Production by Country and Year\n",
    "\n",
    "Code uses a pivot table with the country names as the index, year as the columns, and beef stocks as the values. Then, it uses seaborn to create a heatmap with annotations that display the beef stocks production by country and year. The cmap parameter sets the color palette, and fmt='g' sets the format for the annotations to be in plain numbers. The plt.title(), plt.xlabel(), and plt.ylabel() functions are used to label the heatmap.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Filter the original dataset to keep only data for Ireland, France, and Germany from 2000 onwards\n",
    "beef_df = df.loc[df['Country'].isin(['Ireland', 'France', 'Germany']) & (df['Year'] >= 2000)]\n",
    "\n",
    "# 2. Group the filtered dataset by year and country and calculate the total beef production for each group\n",
    "beef_production = beef_df.groupby(['Year', 'Country'])['Stocks'].sum().reset_index()\n",
    "\n",
    "# 3. Create separate line charts for each country\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('dark')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(data=beef_production, x='Year', y='Stocks', hue='Country', ax=ax)\n",
    "\n",
    "# 4. Compare the trends in beef production over time for each country\n",
    "plt.title('Beef Production in Ireland, France, and Germany since 2000')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Beef Production (in 1000 metric tons)')\n",
    "plt.legend(title='Country')\n",
    "\n",
    "# 5. Summarize your findings and draw conclusions about the similarities and differences in beef production among the three countries since 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Country')# groups the DataFrame by one or more columns and applies a function to each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert dataframe to list of lists\n",
    "table = ds.values.tolist()\n",
    "\n",
    "\n",
    "\n",
    "# use tabulate to create a table\n",
    "print(tabulate(table, headers, tablefmt='latex_booktabs'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Pandas DataFrame,'df' in latex table out\n",
    "table = tabulate(df.sample(40), headers='keys', tablefmt='latex', floatfmt=\".2f\")\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_rotated_table(df: pd.DataFrame, caption: str, label: str) -> str:\n",
    "    # Start the LaTeX tabular environment\n",
    "    latex = \"\\\\begin{table}[h]\\n\"\n",
    "    latex += \"\\\\centering\\n\"\n",
    "    latex += \"\\\\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}\\n\"\n",
    "    latex += \"\\\\hline\\n\"\n",
    "    \n",
    "    # Add the table headers\n",
    "    headers = list(df.columns)\n",
    "    for header in headers:\n",
    "        latex += \"\\\\rotatebox{90}{\" + header + \"} & \"\n",
    "    latex = latex[:-2] + \"\\\\\\\\\\n\"\n",
    "    latex += \"\\\\hline\\n\"\n",
    "    \n",
    "    # Add the table rows\n",
    "    for row in df.iterrows():\n",
    "        latex += \" & \".join([str(item) for item in row[1]]) + \" \\\\\\\\\\n\"\n",
    "    \n",
    "    # End the LaTeX tabular environment and add the caption and label\n",
    "    latex += \"\\\\hline\\n\"\n",
    "    latex += \"\\\\end{tabular}\\n\"\n",
    "    latex += \"\\\\caption{\" + caption + \"}\\n\"\n",
    "    latex += \"\\\\label{\" + label + \"}\\n\"\n",
    "    latex += \"\\\\end{table}\"\n",
    "    \n",
    "    return latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume your data is in a pandas DataFrame called 'df'\n",
    "table = tabulate(livestock, headers='keys', tablefmt='latex', floatfmt=\".2f\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_rotated_table(df.sample(40),'Sample of Livestock data before EDA','tab:livestock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert df to a LaTeX table\n",
    "table = tabulate(df, headers='keys', tablefmt='latex')\n",
    "# Print the LaTeX table\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop Belgium-Luxembourg\n",
    "# Drop \"Production\" column\n",
    "df = df.drop(df[df['Area'] == 'Belgium-Luxembourg'].index)\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of the DataFrame\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of unique countries from the \"Area\" column\n",
    "countries = df['Area'].unique()\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# count the number of missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# print the result\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of areas with missing values\n",
    "num_missing_areas = df['Area'][df.isna().any(axis=1)].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(\"The number of areas with missing values is:\", num_missing_areas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "31900/1708 # 20% data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snake('Distribution of Missing Values by Area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snake('msno.matrix(df)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a bar chart of the missing value counts by year\n",
    "plt.figure(figsize=(20,8))  # increase the figure size for better readability\n",
    "ax = year_counts.plot(kind='bar')\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Number of Missing Values', fontsize=14)\n",
    "plt.title('Distribution of Missing Values by Year', fontsize=18)\n",
    "plt.xticks(rotation=0, fontsize=12)  # rotate x-axis labels to 0 degrees\n",
    "ax.tick_params(axis='y', labelsize=12)  # adjust y-axis label size\n",
    "ax.tick_params(axis='x', pad=10)  # adjust x-axis tick padding\n",
    "\n",
    "# add value labels to the bars\n",
    "for i, v in enumerate(year_counts):\n",
    "    ax.text(i, v, str(v), ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "\n",
    "# set year labels vertically\n",
    "ax.set_xticklabels(year_counts.index, rotation=90)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "A new dataframe with counts of missing values \n",
    "for each country was sorted in descending order\n",
    "revealing  the top 10 countries\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# create a new dataframe to hold the counts of missing values by country\n",
    "country_counts = df.isnull().sum(axis=1).groupby(df.Area).sum().sort_values(ascending=False)\n",
    "\n",
    "# get the top 10 countries with the most missing values\n",
    "top_10_countries = country_counts.head(10)\n",
    "\n",
    "# print the list of top 10 countries\n",
    "print(top_10_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe to hold the counts of missing values by country\n",
    "country_counts = df.isnull().sum(axis=1).groupby(df.Area).sum().sort_values(ascending=True)\n",
    "\n",
    "# get the list of countries with any missing values\n",
    "missing_countries = country_counts[country_counts > 0].index\n",
    "\n",
    "# print the list of countries with missing values\n",
    "print(\"Countries with missing values:\\n\", missing_countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe to hold the counts of missing values by country\n",
    "country_counts = df.isnull().sum(axis=1).groupby(df.Area).sum().sort_values(ascending=True)\n",
    "\n",
    "# get the list of countries with any missing values\n",
    "missing_countries = country_counts[country_counts > 0].index\n",
    "\n",
    "# print the list of countries with missing values\n",
    "print(\"Countries with missing values:\\n\", missing_countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe to hold the counts of missing values by country\n",
    "country_counts = df.isnull().sum(axis=1).groupby(df.Area).sum().sort_values(ascending=True)\n",
    "\n",
    "# get the list of countries with any missing values\n",
    "missing_countries = country_counts[country_counts > 0]\n",
    "\n",
    "# create a new dataframe with the missing value counts and the total number of observations for each country\n",
    "mv_counts = pd.concat([missing_countries, df.groupby('Area').size()], axis=1)\n",
    "mv_counts.columns = ['Missing Values', 'Total Observations']\n",
    "\n",
    "# calculate the proportion of missing values for each country\n",
    "mv_counts['% Missing'] = mv_counts['Missing Values'] / mv_counts['Total Observations'] * 100\n",
    "\n",
    "# sort the dataframe by the proportion of missing values in descending order\n",
    "mv_counts = mv_counts.sort_values('% Missing', ascending=False)\n",
    "\n",
    "# display the table\n",
    "print(mv_counts.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# group the data by Area and compute the total count of missing values for each group\n",
    "area_counts = df.isnull().sum(axis=1).groupby(df.Area).sum()\n",
    "\n",
    "# create a bar chart of the missing value counts by Area\n",
    "plt.figure(figsize=(10,5))\n",
    "ax = area_counts.plot(kind='bar')\n",
    "plt.xlabel('Area')\n",
    "plt.ylabel('Number of Missing Values')\n",
    "plt.title('Distribution of Missing Values by Area')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# add value labels to the bars\n",
    "for i, v in enumerate(area_counts):\n",
    "    ax.text(i, v, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#### Title \n",
    "The 'title' naming convention is where each word starts\n",
    "with a capital letter, except for prepositions and conjunctions, which start with a lowercase letter. \n",
    "The function takes a string as input and converts it to title case, \n",
    "where the first letter of each non-conjunction/preposition word is capitalized, and all other letters are lowercase.\n",
    "It achieves this by splitting the input string into a list of words, identifying which words are prepositions or conjunctions based on a predefined list, and then capitalizing the first letter of all other words while converting prepositions and conjunctions to lowercase. The resulting list of processed words is then joined back into a single string with proper spacing and returned.\n",
    "\"\"\"\n",
    "def title(sentence):\n",
    "    \"\"\"\n",
    "    Takes a string and converts it to title case, where the first letter of each\n",
    "    non-conjunction/preposition word is capitalized, and all other letters are lowercase.\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): The string to convert to title case.\n",
    "        \n",
    "    Returns:\n",
    "        str: The input string converted to title case.\n",
    "    \"\"\"\n",
    "    # Define a list of common prepositions and conjunctions\n",
    "    prepositions_conjunctions = ['a', 'this', 'an', 'the', 'and', 'but', 'or', 'for', 'has', 'nor', 'on', 'at', 'to', 'from', 'by', 'over', 'under', 'in', 'out', 'of']\n",
    "    # Split the input string into a list of words\n",
    "    words = sentence.split()\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        # If the word is not a preposition or conjunction, capitalize the first letter and lowercase the rest\n",
    "        if word.lower() not in prepositions_conjunctions:\n",
    "            processed_words.append(word.capitalize())\n",
    "        # If the word is a preposition or conjunction, convert to lowercase\n",
    "        else:\n",
    "            processed_words.append(word.lower())\n",
    "    # Join the list of processed words into a single string, with proper spacing\n",
    "    output = \" \".join(processed_words)\n",
    "    # Remove any leading/trailing whitespace and add some padding\n",
    "    return \"     \" + re.sub('\\s+', ' ', output.strip()) + \"     \"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_describtions = df['Flag Description'].unique()\n",
    "print(unique_describtions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[df['Year'] > 1999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Key'] = df['Area'] + '_' + df['Year'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_values = df['Flag Description'].unique()\n",
    "print(flag_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Domain Code', 'Domain', 'Area Code (M49)', 'Element Code', 'Element', 'Item Code (CPC)', 'Year Code', 'Year', 'Unit', 'Flag Description'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# count the frequency of NaN and 'Official figure' values in the 'Flag Description' column\n",
    "flag_counts = df['Flag Description'].value_counts(dropna=False)\n",
    "\n",
    "# plot a pie chart of the flag counts\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(flag_counts, labels=flag_counts.index, autopct='%1.1f%%')\n",
    "plt.title('Flag Description Frequencies')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_countries = df[df.isna().any(axis=1)]['Area'].unique()\n",
    "\n",
    "print(nan_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_areas = df['Area'].unique()\n",
    "print(unique_areas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_data = df[df['Area'] == 'Belgium-Luxembourg']\n",
    "bl_data.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luxembourg_data = df[df[\"Area\"] == \"Luxembourg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Area\"] == \"Luxembourg\"].head(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Area'] == 'Belgium'].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_areas = df['Area'].nunique()\n",
    "print('Number of unique areas:', num_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows for Belgium-Luxembourg\n",
    "df = df.drop(index=df[df[\"Area\"] == \"Belgium-Luxembourg\"].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "removeing extraneous columns\n",
    "\"\"\"\n",
    "\n",
    "df = df.drop(['flag','Domain Code', 'Domain', 'Area Code (M49)', 'Element Code', 'Element', 'Item Code (CPC)', 'Year Code', 'Year', 'Unit', 'Flag Description'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"  \n",
    "####  Transform \n",
    "\n",
    "The transform function reads in a CSV file, renames a column, \n",
    "and filters the resulting dataframe to only include the 'key' \n",
    "and specified column. It returns the resulting dataframe after\n",
    "renaming the specified column and filtering.\n",
    "\"\"\"\n",
    "\n",
    "def transform(path: str, filename: str, col_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Reads in a CSV file from the given directory, renames a column to the given column name, and\n",
    "    filters the resulting dataframe to only include the 'key' and specified column.\n",
    "    \n",
    "    Args:\n",
    "        path (str): The relative path of the directory containing the data.\n",
    "        filename (str): The name of the CSV file to read in.\n",
    "        col_name (str): The name to assign to the specified column in the resulting dataframe.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: The resulting dataframe after renaming the specified column and filtering\n",
    "        to only include the 'key' and specified column.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = os.path.join(path, filename)\n",
    "        df = pd.read_csv(file_path, on_bad_lines='skip', skiprows=1)\n",
    "        df.rename(columns={'Unnamed: 0': 'Year'}, inplace=True)\n",
    "        df['key'] = df.columns[1] + df['Year'].astype(str)\n",
    "        df.rename(columns={df.columns[1]: col_name}, inplace=True)\n",
    "        df = df.filter(['key', col_name])\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading in CSV file {file_path}: {e}\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "####  Combine Files\n",
    "\n",
    "The combine function is designed to read in all  the **precicipitation**\n",
    "or **mean-temperature** CSV files  from either the 'pr' or 'ts' folders,\n",
    "apply the transform function to each file to rename a column with the country \n",
    "the data relates to and filter at the superregional level. It then combines    \n",
    "all the the resulting dataframes together into a single dataframe for all the 27 EU counties.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def combine(path: str, subfolder: str, col_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Reads in all CSV files in the given subfolder of the directory, applies the 'transform' function to each file, and\n",
    "    combines the resulting dataframes together into a single dataframe.\n",
    "    \n",
    "    Args:\n",
    "        path (str): The relative path of the directory containing the data.\n",
    "        subfolder (str): The name of the subfolder within the directory to read the CSV files from.\n",
    "        col_name (str): The name to assign to the specified column in the resulting dataframe.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: The resulting dataframe after combining data from all CSV files in the\n",
    "        specified subfolder.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        folder_path = os.path.join(path, subfolder)\n",
    "        csv_filenames = glob.glob(folder_path + \"/*.csv\")\n",
    "        processed_dfs = (transform(path, os.path.join(subfolder, os.path.basename(FileName)), col_name) for FileName in csv_filenames)\n",
    "        df = pd.concat(processed_dfs, ignore_index=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error combining CSV files in folder {folder_path}: {e}\")\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#### Temp °C  Preparation\n",
    "\n",
    "All 27 'pr_timeseries_annual_cru' and 27 'tas_timeseries_annual_cru' \n",
    "files will be processed into 'rain.df' &'rain.csv' and 'temp.df' & 'temp.csv' accordingly.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Load the 'tas' data from the '../data' directory and create a dataframe 'temp_df'\n",
    "# with the 'Temp °C' data. \n",
    "temp_df = combine('../data', 'tas', 'Temp \\u00B0C')\n",
    "\n",
    "# Display the first few rows of the 'temp_df' dataframe.\n",
    "temp_df.head()\n",
    "\n",
    "# Save the 'temp_df' dataframe to a CSV file in the '../data/processed' directory, \n",
    "# with the filename 'temp.csv', and exclude the index column from the output.\n",
    "temp_df.to_csv('../data/processed/temp.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the 'temp_df' dataframe again.\n",
    "temp_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#### Rain Preparation\n",
    "\n",
    "All 27 Rain CSVs are processed into rain.df and rain.csv.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Load the 'pr' data from the '../data' directory and create a dataframe 'rain_df'\n",
    "# with the 'Rain_mm/yr' data. \n",
    "rain_df = combine('../data', 'pr', 'Rain_mm/yr')\n",
    "\n",
    "# Display the first few rows of the 'rain_df' dataframe.\n",
    "rain_df.head()\n",
    "\n",
    "# Save the 'rain_df' dataframe to a CSV file in the '../data/processed' directory, \n",
    "# with the filename 'rain.csv', and exclude the index column from the output.\n",
    "rain_df.to_csv('../data/processed/rain.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the 'rain_df' dataframe again.\n",
    "rain_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only data from 2000 and later\n",
    "beef_df = beef_df[beef_df['Year'] >= 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=beef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the column titles\n",
    "cols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanp() # scans the processed folder in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Input/Output:\n",
    "- readr()\n",
    "- scan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning:\n",
    "- camel()\n",
    "- pascal()\n",
    "- snake()\n",
    "- clean_df()\n",
    "- eu()\n",
    "- now2()\n",
    "- split_file_name()\n",
    "- splitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration:\n",
    "- filter_col_by_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "- eu()\n",
    "- transform\n",
    "- get_annual_aggregates()\n",
    "- get_dfs()\n",
    "- get_multi_index_df()\n",
    "- get_ranking_df()\n",
    "- pivot_table_aggregate()\n",
    "- prepare_wealth_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split\n",
    "The split function takes a pandas DataFrame df and a column name col as input, and returns a dictionary where each key corresponds to a unique value in the specified column, and each value is a DataFrame containing all rows with that unique value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "#### Split\n",
    "The split function takes a pandas DataFrame df and a column name col as input, and returns a dictionary where each key corresponds to a unique value in the specified column, and each value is a DataFrame containing all rows with that unique value.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def split(df: pd.DataFrame, col: str) -> dict:\n",
    "    \"\"\"\n",
    "    \n",
    " \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to split.\n",
    "        col (str): The name of the column to group by.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where each key corresponds to a unique value in the specified column,\n",
    "        and each value is a DataFrame containing all rows with that unique value.\n",
    "    \"\"\"\n",
    "    dfs = dict(tuple(df.groupby(col)))\n",
    "    return dfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def now2(df):\n",
    "    \"\"\"\n",
    "    Filter to 'Year' >= 2000.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame to filter.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: The filtered DataFrame.\n",
    "    \"\"\"\n",
    "    year_min = 2000\n",
    "    return df[df['Year'] >= year_min]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Combination:\n",
    "- merge_dfs()\n",
    "- combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Snake\n",
    "\n",
    "\n",
    "def snake(text, default='default'):\n",
    "    \"\"\"\n",
    "    Converts a given string to snake_case by replacing any whitespace characters with underscores,\n",
    "    converting to all lowercase, and removing any non-alphanumeric characters from the beginning and end.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The string to convert to snake_case.\n",
    "        default (str): The default value to return if the input text is empty.\n",
    "\n",
    "    Returns:\n",
    "        str: The resulting string in snake_case format, or the default value if the input text is empty.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return default\n",
    "    # Convert to string and replace any non-alphanumeric characters at the beginning and end with an empty string\n",
    "    text = re.sub(r'^\\W+|\\W+$', '', str(text))\n",
    "    # Replace any period symbols with underscores\n",
    "    text = text.replace('.', '')\n",
    "    # Replace any other non-alphanumeric characters with empty strings\n",
    "    text = re.sub(r'\\W+', '_', text)\n",
    "    # Convert to all lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Example usage:\n",
    "text = \"This is a text with periods. (And other characters.)\"\n",
    "result = snake(text)\n",
    "print(result)  # Output: \"this_is_a_text_with_periods_and_other_characters\"\n",
    "\n",
    "\n",
    "# snake('does snake Work')\n",
    "\n",
    "# snake('                  ')\n",
    "# snake('                  ')\n",
    "# snake('                  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snake('\"This is a text with periods. (And other characters.)\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Pascal\n",
    "The 'pascal' naming function takes in a string as input and converts it to a PascalCase format. PascalCase is a naming convention where the first letter of each word is capitalized, and there are no spaces or separators between the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pascal(string):\n",
    "    \"\"\"\n",
    "    Convert a space- or snake-separated string to PascalCase.\n",
    "\n",
    "    Parameters:\n",
    "        string (str): The input string to convert to PascalCase.\n",
    "\n",
    "    Returns:\n",
    "        str: The input string in PascalCase format.\n",
    "\n",
    "    \"\"\"\n",
    "    # Replace any underscores with spaces\n",
    "    string = string.replace(\"_\", \" \")\n",
    "    # Capitalize the first letter of each word\n",
    "    words = string.title()\n",
    "    # Remove any remaining spaces\n",
    "    words = words.replace(\" \", \"\")\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#### Camel\n",
    "\n",
    "Camel case is a naming convention in which each word in a compound word is capitalized, except for the first word which is in lower case. It is commonly used in programming languages for naming variables and functions.\n",
    "\n",
    "handles both snake_case and space-separated strings\n",
    "\"\"\"\n",
    "def camel(string):\n",
    "    \"\"\"\n",
    "    Convert a space-separated or snake_case string to camelCase.\n",
    "\n",
    "    Parameters:\n",
    "        string (str): The string to convert.\n",
    "\n",
    "    Returns:\n",
    "        str: The converted string in camelCase.\n",
    "    \"\"\"\n",
    "    # Replace underscores with spaces and split the string into a list of words\n",
    "    words = string.replace(\"_\", \" \").split()\n",
    "    # Convert the first word to lowercase and capitalize all subsequent words\n",
    "    camel_cased = [words[0].lower()] + [word.capitalize() for word in words[1:]]\n",
    "    # Concatenate the words together and return the resulting string\n",
    "    return \"    \" + ''.join(camel_cased) + \"    \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_count(string):\n",
    "    \"\"\"\n",
    "    Count the number of characters in a string.\n",
    "\n",
    "    Parameters:\n",
    "    - string (str): The string to count characters in.\n",
    "\n",
    "    Returns:\n",
    "    - int: The number of characters in the string.\n",
    "    \"\"\"\n",
    "    return len(string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Scanners,  Readers and Writers\n",
    "#### Scanners\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Readers\n",
    "\n",
    "'read_csv' is a function in the Pandas library for reading in CSV (Comma Separated Values) files into a DataFrame. It is a flexible function that can handle a variety of input formats, including different delimiters, encodings, and line endings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(file_name: str) -> Tuple[Dict[str, pd.DataFrame], List[str]]:\n",
    "    \"\"\"\n",
    "    Splits a CSV file into multiple dataframes based on the unique values in the 'Element' column.\n",
    "    \n",
    "    Parameters:\n",
    "        file_name (str): The name of the CSV file to read in.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[Dict[str, pd.DataFrame], List[str]]: A tuple containing a dictionary where each key corresponds\n",
    "        to a unique value in the 'Element' column, and each value is a dataframe containing all rows with that\n",
    "        unique value, and a list of unique values in the 'Element' column.\n",
    "    \"\"\"\n",
    "    if not file_name.endswith('.csv'):\n",
    "        raise ValueError('Input file must be a .csv file')\n",
    "    \n",
    "    # Load the specified dataframe\n",
    "    df = pd.read_csv(f'../data/raw/{file_name}')\n",
    "    \n",
    "    # Group the dataframe by the 'Element' column\n",
    "    dfs = dict(tuple(df.groupby('Element')))\n",
    "    \n",
    "    # Get the unique values in the 'Element' column\n",
    "    elements = list(df['Element'].unique())\n",
    "    \n",
    "    return dfs, elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_elementr(file_name: str) -> Tuple[Dict[str, pd.DataFrame], List[str]]:\n",
    "    \"\"\"\n",
    "    Splits a CSV file into multiple dataframes based on the unique values in the 'Element' column.\n",
    "    \n",
    "    Parameters:\n",
    "        file_name (str): The name of the CSV file to read in.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[Dict[str, pd.DataFrame], List[str]]: A tuple containing a dictionary where each key corresponds\n",
    "        to a unique value in the 'Element' column, and each value is a dataframe containing all rows with that\n",
    "        unique value, and a list of unique values in the 'Element' column.\n",
    "    \"\"\"\n",
    "    # Load the specified dataframe\n",
    "    df = pd.read_csv(f'../data/raw/{file_name}')\n",
    "    \n",
    "    # Group the dataframe by the 'Element' column\n",
    "    dfs = dict(tuple(df.groupby('Element')))\n",
    "    \n",
    "    # Get the unique values in the 'Element' column\n",
    "    elements = list(df['Element'].unique())\n",
    "    \n",
    "    return dfs, elements\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_by_element(df: pd.DataFrame) -> Tuple[Dict[str, pd.DataFrame], List[str]]:\n",
    "    \"\"\"\n",
    "    Splits a DataFrame into multiple dataframes based on the unique values in the 'Element' column.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to split.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[Dict[str, pd.DataFrame], List[str]]: A tuple containing a dictionary where each key corresponds\n",
    "        to a unique value in the 'Element' column, and each value is a dataframe containing all rows with that\n",
    "        unique value, and a list of unique values in the 'Element' column.\n",
    "    \"\"\"\n",
    "    # Group the dataframe by the 'Element' column\n",
    "    dfs = dict(tuple(df.groupby('Element')))\n",
    "    \n",
    "    # Get the unique values in the 'Element' column\n",
    "    elements = list(df['Element'].unique())\n",
    "    \n",
    "    return dfs, elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupdf(df, column_name):\n",
    "    # Group the dataframe by the specified column\n",
    "    dfs = dict(tuple(df.groupby(column_name)))\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Delete\n",
    "\n",
    "In this code, we use the os module to delete a file at the specified file path. We first check if the file exists using the os.path.exists() function. If the file exists, we delete it using the os.remove() function. If the file does not exist, we print a message indicating that the file was not found.\n",
    "\n",
    "Note that this code permanently deletes the file, so you should use it with caution. Once a file is deleted, it cannot be easily recovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def delete(file_name):\n",
    "    file_path = os.path.join(\"..\", \"data\", \"raw\", file_name)\n",
    "    expected_ext = \".csv\"\n",
    "    if not file_path.endswith(expected_ext):\n",
    "        print(\"Error: Invalid file extension. File extension must be .csv.\")\n",
    "    elif os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(f\"{file_name} deleted successfully\")\n",
    "    else:\n",
    "        print(f\"{file_name} not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename\n",
    "\n",
    "This function first constructs the file_path by joining the ../data/raw directory with the given file_name. It then sets the expected file extension to .csv. The function then checks if the file_path ends with the expected file extension. If it doesn't, the function prints an error message. If it does, the function checks if the file exists at file_path, and if it does, it removes it and prints a success message. If the file doesn't exist, the function prints a \"not found\" message. like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(old_filename, new_filename):\n",
    "    old_file_path = os.path.join(\"..\", \"data\", old_filename)\n",
    "    new_file_path = os.path.join(\"..\", \"data\", new_filename)\n",
    "    try:\n",
    "        os.rename(old_file_path, new_file_path)\n",
    "        print(f\"{old_filename} renamed to {new_filename} successfully\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{old_filename} not found\")\n",
    "    except FileExistsError:\n",
    "        print(f\"A file with the name {new_filename} already exists\")\n",
    "    except OSError:\n",
    "        print(\"Invalid file path or name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(input_str, find_str, replace_str):\n",
    "    output_str = re.sub(find_str, replace_str, input_str)\n",
    "    \n",
    "    if output_str == input_str:\n",
    "        warnings.warn(\"Replacement unsuccessful: '{}' not found in input string.\".format(find_str))\n",
    "    \n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  tabler\n",
    "\n",
    "\"\"\"The code defines a function tabler that generates an HTML table with information on the files in a given folder and\n",
    "adds a section header that contains the directory path \n",
    "\"\"\"\n",
    "\n",
    "def tabler(folder_path):\n",
    "    \"\"\"\n",
    "    Generate an HTML table with information on files in a given folder.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): The path to the folder containing the files.\n",
    "\n",
    "    Returns:\n",
    "    - str: The HTML code for the table.\n",
    "    \"\"\"\n",
    "    # Get the contents of the folder\n",
    "    try:\n",
    "        contents = os.listdir(folder_path)\n",
    "    except FileNotFoundError:\n",
    "        return \"Directory not found\"\n",
    "    except OSError:\n",
    "        return \"Invalid folder path\"\n",
    "\n",
    "    # Create the section header\n",
    "    header = f\"### {folder_path}\\n\\n\"\n",
    "\n",
    "    # Create the table header\n",
    "    table = '<table style=\"font-size:100%\"><thead><tr><th>File Name</th><th>Size</th><th>Modified Time</th></tr></thead><tbody>'\n",
    "\n",
    "    # Add a row for each file\n",
    "    for item in contents:\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        if os.path.isfile(item_path):\n",
    "            # Get the file size and modified time\n",
    "            size_bytes = os.path.getsize(item_path)\n",
    "            size_kb = size_bytes / 1024\n",
    "            size_str = '{:,.2f} KB'.format(size_kb)\n",
    "            modified_time = datetime.datetime.fromtimestamp(os.path.getmtime(item_path)).strftime('%Y-%m-%d %H:%M')\n",
    "            # Add a row to the table\n",
    "            table += '<tr><td>{}</td><td>{}</td><td>{}</td></tr>'.format(item, size_str, modified_time)\n",
    "\n",
    "    # Close the table\n",
    "    table += '</tbody></table>'\n",
    "\n",
    "    return header + table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beef(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns a Pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): The path to the CSV file to read.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The resulting DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "- eu(df)\n",
    "- now2(df)\n",
    "- split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  String Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File System Operations\n",
    "\n",
    "\n",
    "These functions are responsible for performing various operations on the file system.\n",
    "scan(): Scans a specified folder and prints contents information.\n",
    "tabler(): Generates an HTML table with information on files in a given folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### eu\n",
    "def eu(df):\n",
    "    \"\"\"\n",
    "    Filter a pandas DataFrame to include only the rows where the 'Area' column contains values that match the countries in the European Union.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame to filter.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: The filtered DataFrame.\n",
    "    \"\"\"\n",
    "    country_list = ['Austria', 'Belgium', 'Bulgaria', 'Croatia', 'Cyprus', 'Czechia', 'Denmark', \n",
    "                    'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Hungary', 'Ireland', 'Italy', \n",
    "                    'Latvia', 'Lithuania', 'Luxembourg', 'Malta', 'Netherlands', 'Poland', 'Portugal', 'Romania', \n",
    "                    'Slovakia', 'Slovenia', 'Spain', 'Sweden']\n",
    "    return df[df['Area'].isin(country_list)]\n",
    "\n",
    "# df=readr('meat','df')\n",
    "# df=eu(df)\n",
    "# df\n",
    "++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def now(df, year_min):\n",
    "    \"\"\"\n",
    "    Filter to 'Year'>.\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame to filter.\n",
    "    - year_min (int): The minimum year to include in the filtered DataFrame.\n",
    "    Returns:\n",
    "    - pandas.DataFrame: The filtered DataFrame.\n",
    "    \"\"\"\n",
    "    return df[df['Year'] >= year_min]\n",
    "\n",
    "# df=readr('meat','df')\n",
    "# df = now(df, 2015)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and  comparison of Ireland's beef sector with other  EU contries\n",
    "\n",
    "![image1](../images/tu04.png)\n",
    "\n",
    "<span style=\"font-size: 24px;\">                 </span>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we carry out the first 6 stages in the followning list@\n",
    "\n",
    "1. Reading - export, import, trade imbalance, arable production, animal stock\n",
    "2. Cleaning\n",
    "3. Transformation\n",
    "4. Splitting\n",
    "5. Aggregation\n",
    "6. Analysis\n",
    "7. Visualization\n",
    "8. Modeling and Machine Learning\n",
    "9. Forecasting\n",
    "10. Sentiment Analysis\n",
    "11. Evidence Based Recommendations\n",
    "12. Process Rationale\n",
    "13. Ireland as your baseline.\n",
    "\n",
    "\n",
    "## Modules Functions Libraries and How to Use\n",
    "\n",
    "Before starting the exploratory data analysis (EDA), make sure to execute all necessary module imports, libraries, and functions. This will ensure all  required dependencies and tools to perform analysis are operational.\n",
    "To execute all necessary module imports, libraries, and functions before starting the exploratory data analysis (EDA) \n",
    "**Restart & run all** as convention of dependancy order was broken for organisational purposes! On my part that is! Sorry!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Reading\n",
    "2. Data Cleaning\n",
    "3. Data Transformation\n",
    "4. Data Splitting\n",
    "5. Data Aggregation\n",
    "6. Data Analysis\n",
    "7. Data Visualization\n",
    "8. Modeling and Machine Learning\n",
    "9. Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAOSTAT Data Domains \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"../images/we16.png\" alt=\"image7\" width=\"80%\">\n",
    "\n",
    "[<span style=\"font-size: 18px;\">Figure 2:Data Domain Table view of FAOSTAT</span>\n",
    "](https://www.fao.org/faostat/en/#data/domains_table)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The [FAOSTAT Data Domains](https://www.fao.org/faostat/en/#data/domains_table)  are organised as follows:\n",
    "\n",
    "  -  Production: Production of crops and livestock products, including production indices and the value of agricultural production.\n",
    "\n",
    "  - Food Security and Nutrition: Information on SDG indicators related to food security and nutrition and food balances.\n",
    "\n",
    "  - Trade: Including detailed trade matrices, trade indices, and updates on related data.\n",
    "\n",
    "  - Prices: Producer and   consumer price indices, deflators, and exchange rates.\n",
    "\n",
    "  - Land, Inputs and Sustainability:Land use, land cover, inputs, including fertilizers and manure and pesticides.\n",
    "  \n",
    "  - Population and Employment: Annual population including those specific to agriculture and rural areas.\n",
    "\n",
    "  - Investment: Government expenditure, credit to agriculture, foreign direct investment, and country investment statistics.\n",
    "\n",
    "  - Macro-Economic Indicators: Such as capital stock.\n",
    "\n",
    "  - Food Value Chain: This domain provides information on the value shares of the food industry and primary factors.\n",
    "\n",
    "  - Climate Change: Emissions, crop residues, forests, and other indicators related to climate change.\n",
    "\n",
    "  - Forestry: Forestry production and trade, as well as forestry trade flows.\n",
    "\n",
    "  - SDG Indicators: The Sustainable Development Goals (SDGs) are a set of 17 goals established by the United Nations in 2015.\n",
    "\n",
    "  - World Census of Agriculture: This domain provides structural data from agricultural censuses taken around the world\n",
    "\n",
    "  - Discontinued archives and data series: This includes data on indicators from surveys and research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate  Data Preparation \n",
    "\n",
    "<img src=\"../images/tu03.png\" alt=\"image5\" width=\"50%\">\n",
    "<span style=\"font-size: 24px;\">                  </span>\n",
    " Only two attributes are taken from the CCKP database: Mean_Temperature and Precipitation.\n",
    "\n",
    "[The CCKP website](https://climateknowledgeportal.worldbank.org/)\n",
    " is a  resource for information on the impacts of climate change and the actions taken to address these impacts. While this is outside the remit of this project the CCKP also provides access to global data on a historical  basis for the **Mean_Temperature** and **Precipitation** at the  country-by-country level  on both monthly and yearly aggregates. While **humidity** is also a known influential predictor variable these two should have a statistically significant imapct on our predictive modelling. Spatial data is provided as a global NetCDF file, with Climatology, Timeseries and Heatplot data is provided as a CSV file.\n",
    "\n",
    "Climate conditions, such as average temperature and rainfall (precipitation ) can greatly affect the growth and health of cattle. Precipitation and temperature predictor variables were  retrieved  but they were   aggragated by country and this necessitated  the **cckp** and  **combine**  functions for data wrangling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  About FAOSTAT\n",
    "\n",
    "<img src=\"../images/tu02.png\" alt=\"image5\" width=\"50%\">\n",
    "\n",
    "<span style=\"font-size: 24px;\">                  </span>\n",
    "FAOSTAT is a comprehensive database maintained by the Food and Agriculture Organization of the United Nations (FAO), providing timely, reliable data on agriculture, food, and nutrition for over 200 countries. Its information is used to inform decision-making, policy formulation, and research in the field, covering topics such as production, trade, and fertilizer use. FAOSTAT is a valuable resource for governments, organizations, researchers, and the public, informing policy and interventions to enhance food security and reduce poverty.\n",
    "\n",
    "#### Licencing \n",
    "All datasets from the [FAOSTAT](https://www.fao.org/faostat/en/#home) are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 IGO [(CC BY-NC-SA 3.0 IGO)](https://creativecommons.org/licenses/by-nc-sa/3.0/igo/). Source: FAOSTAT (2023). Time Series datasets.\n",
    "<img src=\"../images/tu06.png\" alt=\"image5\" width=\"50%\">\n",
    "<span style=\"font-size: 24px;\">                  </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "####   CCKP Data  and an initial bit of EDA\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "  <img src=\"../images/we28.png\" alt=\"image19\" style=\"width: 30%;\">\n",
    "  <img src=\"../images/we29.png\" alt=\"image20\" style=\"width: 30%;\">\n",
    "    <img src=\"../images/we30.png\" alt=\"image20\" style=\"width: 30%;\">\n",
    "</div>\n",
    "\n",
    "<span style=\"font-size: 18px;\">Figure 3:Time Series Data downloaded for 27 EU countries from  CCKP site </span>\n",
    "\n",
    "\n",
    "To maintain consistency with the FAO data, annual and not monthly time series  aggregates were taken from the Climatic Research Unit (CRU) dataset for **precipitation** and   **mean-temperature**. These datasets are provided by the CRU TS 4.04 dataset, a gridded climate dataset produced by the Climatic Research Unit (CRU) at the University of East Anglia in the United Kingdom. In the statistics section, range, variance, and standard deviation of monthly data may be revisited for insights.\n",
    "\n",
    "The file names and folder names of the CCKP data used in this project are tabulated below.\n",
    "\n",
    "<span style=\"font-size: 24px;\">Table : Table shows Time Series data filenames and folders  for 27 EU countries from  CCKP site </span>\n",
    "\n",
    "\n",
    "\n",
    "| Country        | Code | TasAnnual (Folder with Tempature data)                              | PrAnnual   (Folder with Precipitation Data)                        |\n",
    "|:--------------:|:----:|:--------------------------------------:|:---------------------------------:|\n",
    "| Albania        | ALB  | tas_timeseries_annual_cru_1901-2021_ALB.csv | pr_timeseries_annual_cru_1901-2021_ALB.csv |\n",
    "| Andorra        | AND  | tas_timeseries_annual_cru_1901-2021_AND.csv | pr_timeseries_annual_cru_1901-2021_AND.csv |\n",
    "| Austria        | AUT  | tas_timeseries_annual_cru_1901-2021_AUT.csv | pr_timeseries_annual_cru_1901-2021_AUT.csv |\n",
    "| Belarus        | BLR  | tas_timeseries_annual_cru_1901-2021_BLR.csv | pr_timeseries_annual_cru_1901-2021_BLR.csv |\n",
    "| Belgium        | BEL  | tas_timeseries_annual_cru_1901-2021_BEL.csv | pr_timeseries_annual_cru_1901-2021_BEL.csv |\n",
    "| Bosnia and Herzegovina | BIH  | tas_timeseries_annual_cru_1901-2021_BIH.csv | pr_timeseries_annual_cru_1901-2021_BIH.csv |\n",
    "| Bulgaria       | BGR  | tas_timeseries_annual_cru_1901-2021_BGR.csv | pr_timeseries_annual_cru_1901-2021_BGR.csv |\n",
    "| Croatia        | HRV  | tas_timeseries_annual_cru_1901-2021_HRV.csv | pr_timeseries_annual_cru_1901-2021_HRV.csv |\n",
    "| Cyprus         | CYP  | tas_timeseries_annual_cru_1901-2021_CYP.csv | pr_timeseries_annual_cru_1901-2021_CYP.csv |\n",
    "| Czech Republic | CZE  | tas_timeseries_annual_cru_1901-2021_CZE.csv | pr_timeseries_annual_cru_1901-2021_CZE.csv |\n",
    "| Denmark        | DNK  | tas_timeseries_annual_cru_1901-2021_DNK.csv | pr_timeseries_annual_cru_1901-2021_DNK.csv |\n",
    "| Estonia        | EST  | tas_timeseries_annual_cru_1901-2021_EST.csv | pr_timeseries_annual_cru_1901-2021_EST.csv |\n",
    "| Finland        | FIN  | tas_timeseries_annual_cru_1901-2021_FIN.csv | pr_timeseries_annual_cru_1901-2021_FIN.csv |\n",
    "| France         | FRA  | tas_timeseries_annual_cru_1901-2021_FRA.csv | pr_timeseries_annual_cru_1901-2021_FRA.csv |\n",
    "| Germany        | DEU  | tas_timeseries_annual_cru_1901-2021_DEU.csv | pr_timeseries_annual_cru_1901-2021_DEU.csv |\n",
    "| Gibraltar      | GIB  | tas_timeseries_annual_cru_1901-2021_GIB.csv | pr_timeseries_annual_cru_1901-2021_GIB.csv |\n",
    "| Greece | GRC | tas_timeseries_annual_cru_1901-2021_GRC.csv | pr_timeseries_annual_cru_1901-2021_GRC.csv |\n",
    "| Croatia | HRV | tas_timeseries_annual_cru_1901-2021_HRV.csv | pr_timeseries_annual_cru_1901-2021_HRV.csv |\n",
    "| Hungary | HUN | tas_timeseries_annual_cru_1901-2021_HUN.csv | pr_timeseries_annual_cru_1901-2021_HUN.csv |\n",
    "| Ireland | IRL | tas_timeseries_annual_cru_1901-2021_IRL.csv | pr_timeseries_annual_cru_1901-2021_IRL.csv |\n",
    "| Italy | ITA | tas_timeseries_annual_cru_1901-2021_ITA.csv | pr_timeseries_annual_cru_1901-2021_ITA.csv |\n",
    "| Lithuania | LTU | tas_timeseries_annual_cru_1901-2021_LTU.csv | pr_timeseries_annual_cru_1901-2021_LTU.csv |\n",
    "| Luxembourg | LUX | tas_timeseries_annual_cru_1901-2021_LUX.csv | pr_timeseries_annual_cru_1901-2021_LUX.csv |\n",
    "| Latvia | LVA | tas_timeseries_annual_cru_1901-2021_LVA.csv | pr_timeseries_annual_cru_1901-2021_LVA.csv |\n",
    "| Malta | MLT | tas_timeseries_annual_cru_1901-2021_MLT.csv | pr_timeseries_annual_cru_1901-2021_MLT.csv |\n",
    "| Netherlands | NLD | tas_timeseries_annual_cru_1901-2021_NLD.csv | pr_timeseries_annual_cru_1901-2021_NLD.csv |\n",
    "| Poland | POL | tas_timeseries_annual_cru_1901-2021_POL.csv | pr_timeseries_annual_cru_1901-2021_POL.csv |\n",
    "| Portugal | PRT | tas_timeseries_annual_cru_1901-2021_PRT.csv | pr_timeseries_annual_cru_1901-2021_PRT.csv |\n",
    "| Romania | ROU | tas_timeseries_annual_cru_1901-2021_ROU.csv | pr_timeseries_annual_cru_1901-2021_ROU.csv |\n",
    "| Slovakia | SVK | tas_timeseries_annual_cru_1901-2021_SVK.csv | pr_timeseries_annual_cru_1901-2021_SVK.csv |\n",
    "| Slovenia | SVN | tas_timeseries_annual_cru_1901-2021_SVN.csv | pr_timeseries_annual_cru_1901-2021_SVN.csv |\n",
    "| Sweden | SWE | tas_timeseries_annual_cru_1901-2021_SWE.csv | pr_timeseries_annual_cru_1901-2021_SWE.csv |\n",
    "\n",
    "\n",
    "All datasets from the CCKP are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO). \n",
    "Source: CCKP (2023). Time Series datasets. Retrieved from [https://climateknowledgeportal.worldbank.org/download-data]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Data Cleaning           |\n",
    "| -----------------------|\n",
    "| df.dropna()            |\n",
    "| df.fillna()            |\n",
    "| df.clip()              |\n",
    "| df.replace()           |\n",
    "| pd.cut()               |\n",
    "| df.drop_duplicates()   |\n",
    "| df.drop_duplicates()   |\n",
    "| df.fillna()            |\n",
    "| df.merge()             |\n",
    "| df.pivot()             |\n",
    "| df.rename()            |\n",
    "| df.query()             |\n",
    "| df.dropna(axis=0, inplace=True)  |\n",
    "| df['column_name'].interpolate(inplace=True) |\n",
    "| os.listdir('data')     |\n",
    "| N/A                    |\n",
    "\n",
    "| Data Wrangling          |\n",
    "| ------------------------|\n",
    "| df.melt()               |\n",
    "| df.pivot()              |\n",
    "| df.stack()              |\n",
    "| df.unstack()            |\n",
    "| df.astype()             |\n",
    "| df.apply()              |\n",
    "| df.groupby()            |\n",
    "| pd.crosstab()           |\n",
    "| pd.concat()             |\n",
    "| df.replace()            |\n",
    "| df.rename()             |\n",
    "| df.sort_values()        |\n",
    "| df.transform()          |\n",
    "\n",
    "| Data Exploration         |\n",
    "| -------------------------|\n",
    "| df.info()                |\n",
    "| df.describe()            |\n",
    "| df.describe()            |\n",
    "| df.value_counts()        |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "\n",
    "| Data Visualization       |\n",
    "| -------------------------|\n",
    "| plotly.plot()            |\n",
    "| seaborn.plot()           |\n",
    "| ggplot.plot()            |\n",
    "| matplotlib.plot()        |\n",
    "| plot.plot()              |\n",
    "| holoviews.plot()         |\n",
    "| bokeh.plot()             |\n",
    "| plotly.plot()            |\n",
    "| seaborn.plot()           |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "| N/A                      |\n",
    "\n",
    "| Data Transformation       |\n",
    "| --------------------------|\n",
    "| df.log()                  |\n",
    "| df.exp()                  |\n",
    "| df.scale()                |\n",
    "| df.normalize()            |\n",
    "| df.sqrt()                 |\n",
    "| df.abs()                  |\n",
    "| df.abs()                  |\n",
    "| df.divide()               |\n",
    "| df.subtract()             |\n",
    "| df.multiply()             |\n",
    "| df.add()                  |\n",
    "| df.expit()                |\n",
    "| df.cumsum()               |\n",
    "| N/A                       |\n",
    "\n",
    "| Feature Engineering       |\n",
    "| --------------------------|\n",
    "| df.discretize()           |\n",
    "| df.binarize()             |\n",
    "| df.dummies()              |\n",
    "| df.group_enc()            |\n",
    "| df.interactions()         |\n",
    "| df.pca()/df.ica()         |\n",
    "| df.non-linear_trans()     |\n",
    "| df.scaling/discretize()   |\n",
    "| df.rolling_window()       |\n",
    "| N/A                       |\n",
    "\n",
    "| Time Series Analysis       |\n",
    "| --------------------------|\n",
    "| df.pct()                  |\n",
    "| df.shift()                |\n",
    "| df.count()                |\n",
    "| df.rank()                 |\n",
    "| df.zscore()               |\n",
    "| df.frequency()            |\n",
    "| df.rolling()              |\n",
    "| df.autocorr()/df.pacf()   |\n",
    "| N/A                       |\n",
    "| N/A                       |\n",
    "| df.pct_change()           |\n",
    "| df.forecast()             |\n",
    "| N/A                       |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "1012.78px",
    "width": "507.775px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents (Clickable in sidebar)",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "1166.7px",
    "left": "1576px",
    "top": "1389.19px",
    "width": "497px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "890563eb1401dd7c5eac482b2070a231034cb0eabe59bf1a3eb86f9e36919f52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
