{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e346365",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12212\\1531863784.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mland_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m'data/land_use_all_items_area_eu28.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'skip'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# - loads data from the \"land_use_all_items_area_eu28.csv\" file into a pandas DataFrame called land_df. This is the first step in the data analysis pipeline.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Key'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#- merges the df DataFrame with the temperature_df DataFrame on the \"Key\" column. This combines the data from the two DataFrames into a single DataFrame, df, for further analysis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Key'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Country'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Year'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# - adds a new column named \"Key\" to the df DataFrame by concatenating the \"Country\" column with the \"Year\" column converted to a string. This creates a unique identifier for each row in the DataFrame.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "land_df = pd.read_csv( 'data/land_use_all_items_area_eu28.csv', on_bad_lines='skip')# - loads data from the \"land_use_all_items_area_eu28.csv\" file into a pandas DataFrame called land_df. This is the first step in the data analysis pipeline.\n",
    "\n",
    "df = pd.merge(df, temperature_df, on='Key') #- merges the df DataFrame with the temperature_df DataFrame on the \"Key\" column. This combines the data from the two DataFrames into a single DataFrame, df, for further analysis.\n",
    "\n",
    "df['Key'] = df['Country'] + df['Year'].astype(str)# - adds a new column named \"Key\" to the df DataFrame by concatenating the \"Country\" column with the \"Year\" column converted to a string. This creates a unique identifier for each row in the DataFrame.\n",
    "\n",
    "df['Key'] = df['Country'] + df['Year'].astype(str)# - updates the \"Key\" column in the df DataFrame with the concatenated values of \"Country\" and \"Year\". This is probably a duplicate line of code and can be removed.\n",
    "\n",
    "filtered_df = df.loc[(df['A'] > 10) & (df['B'] < 5)] # filters the df DataFrame to only include rows where the value in the \"A\" column is greater than 10 and the value in the \"B\" column is less than 5. This is an example of how to filter a DataFrame across multiple columns.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776697d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sure! Here are the 15 most popular NumPy functions \n",
    "applied to a pandas DataFrame, with short explanatory \n",
    "comments above each code snippet:\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create a sample DataFrame\n",
    "data = {'col1': [1, 2, 3, 4, 5], 'col2': [6, 7, 8, 9, 10], 'col3': [11, 12, 13, 14, 15]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# apply NumPy functions to DataFrame columns\n",
    "df['mean_col'] = df['col1'].apply(np.mean)  # calculate mean of column\n",
    "df['median_col'] = df['col2'].apply(np.median)  # calculate median of column\n",
    "df['std_col'] = df['col3'].apply(np.std)  # calculate standard deviation of column\n",
    "df['min_col'] = df['col1'].apply(np.min)  # calculate minimum of column\n",
    "df['max_col'] = df['col2'].apply(np.max)  # calculate maximum of column\n",
    "df['var_col'] = df['col3'].apply(np.var)  # calculate variance of column\n",
    "df['sin_col'] = df['col1'].apply(np.sin)  # apply sine function to column\n",
    "df['cos_col'] = df['col2'].apply(np.cos)  # apply cosine function to column\n",
    "df['exp_col'] = df['col3'].apply(np.exp)  # apply exponential function to column\n",
    "df['log_col'] = df['col1'].apply(np.log)  # apply natural logarithm function to column\n",
    "df['abs_col'] = df['col2'].apply(np.abs)  # apply absolute value function to column\n",
    "df['square_col'] = df['col3'].apply(np.square)  # apply square function to column\n",
    "df['sqrt_col'] = df['col1'].apply(np.sqrt)  # apply square root function to column\n",
    "df['power_col'] = df['col2'].apply(lambda x: np.power(x, 2))  # apply power function to column\n",
    "df['round_col'] = df['col3'].apply(lambda x: np.round(x, 2))  # round column to 2 decimal places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674ee18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2cd539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd518aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
